WEBVTT

00:00:00.000 --> 00:00:15.800
So willkommen zu sicherer Systeme heute. Es gibt ein paar AnkÃ¼ndigungen zur Mini-Klausur von Maximilian.

00:00:15.800 --> 00:00:21.840
Genau, hallo zusammen. Heute ist die letzte MÃ¶glichkeit sich noch fÃ¼r die Mini-Klausur

00:00:21.840 --> 00:00:27.840
anzumelden. Bis heute Abend 23.59 Uhr habt ihr noch die MÃ¶glichkeit euch fÃ¼r die Mini-Klausur

00:00:27.840 --> 00:00:40.600
anzumelden. Danach ist die Anmeldung zu. Noch Fragen? Das war eindeutig. Gut, vielen Dank.

00:00:40.600 --> 00:00:49.440
Vielleicht mal kurze Handmeldung. Wer hat sich angemeldet von Ihnen schon? Okay,

00:00:49.440 --> 00:01:18.760
das ist die. Danke. So ein Mist ey. Ich hÃ¤nge mir das Ding um. So mÃ¼ssen Sie ein bisschen

00:01:18.760 --> 00:01:25.320
deiser sein. Jetzt nehme ich das andere Mikro. Gut, danke Maximilian. So, dann willkommen

00:01:25.320 --> 00:01:29.320
noch mal zur Sicherung des Stemms heute. Heute machen wir das neue Kapitel. Starten ein neues

00:01:29.320 --> 00:01:35.840
Kapitel. Nummer fÃ¼nf, die angeblich PrivatsphÃ¤re. Letzte Vorlesung vor Weihnachten, nÃ¤chste Woche

00:01:35.840 --> 00:01:42.840
wie gesagt die Mini-Klausur. Eben in der Vorlesung sind wir schon ziemlich weit durch. Heute angeblich

00:01:42.840 --> 00:01:47.440
PrivatsphÃ¤re. NÃ¤chstes Jahr geht es dann fangen wir dann an mit Sicherheitsanalyse, drei Doppelstunden

00:01:47.840 --> 00:01:52.320
und dann haben wir noch Cybercrime, ein oder zwei Doppelstunden, weiÃŸ ich gar nicht genau,

00:01:52.320 --> 00:01:59.040
in der Abschlussvorlesung. Das heiÃŸt im Prinzip sind wir schon durch. Insofern trainieren Sie

00:01:59.040 --> 00:02:03.160
noch mal gut fÃ¼r die Mini-Klausur. Das ist denke ich ein GroÃŸteil der Vorbereitung, der dann auch

00:02:03.160 --> 00:02:10.160
fÃ¼r die Hauptklausur dann sich auszahlen wird. Gut, heute geht es um Anonytheten PrivatsphÃ¤re,

00:02:10.160 --> 00:02:16.080
digitale IdentitÃ¤t, AnonythetsmaÃŸ, Anonyme Kommunikation. Der erste Teil der Vorlesungen,

00:02:16.080 --> 00:02:21.520
da geht es erstmal so um das allgemeine VerstÃ¤ndnis von IdentitÃ¤t und PrivatsphÃ¤re.

00:02:21.520 --> 00:02:26.440
Und im zweiten Teil nach der Pause wird es ein bisschen technischer. Da geht es um anonyme

00:02:26.440 --> 00:02:32.240
Kommunikation, DC-Netze, Mix-Netzwerk und das Tor-Netzwerk als praktisches Beispiel.

00:02:32.800 --> 00:02:47.280
So vielleicht kennen Sie diesen Cartoon aus dem New Yorker, der ist 1983 publiziert worden und

00:02:47.280 --> 00:02:52.120
stammt aus den urauffangszeiten des Internet. Damals konnte man vielleicht noch gar nicht so

00:02:52.120 --> 00:02:57.760
richtig vom Internet sprechen und das drÃ¼ckt das ja auch so ein bisschen aus. Da sagt der eine Hund

00:02:57.760 --> 00:03:04.960
zum anderen on the Internet, nobody knows you're a dog. Das hat so ein bisschen damals in den

00:03:04.960 --> 00:03:12.160
80ern der Auffassung Ausdruck verdienen, dass es eigentlich schwer, also dass das Internet immer

00:03:12.160 --> 00:03:20.960
noch so ein anonymer Raum ist, wo man eintreten kann, niemand weiÃŸ wer die anderen sind. Und ja,

00:03:20.960 --> 00:03:27.360
das war so die Auffassung damals vom Internet. Heutzutage ist das natÃ¼rlich ganz anders. Im

00:03:27.360 --> 00:03:35.560
Internet hat sich verÃ¤ndert seitdem und wÃ¤hrend man damals noch dachte, dass am Internet alles

00:03:35.560 --> 00:03:40.640
natÃ¼rlicherweise anonym ist, weil ja alles elektronisch und digital stattfindet, weiÃŸ

00:03:40.640 --> 00:03:46.800
man heute, dass sowas wie Vertraulichkeit oder auch Privatheit oder AnonymitÃ¤t etwas ist,

00:03:46.800 --> 00:03:50.120
was im Internet vielleicht sogar noch viel schwieriger zu erreichen ist als in der realen

00:03:50.120 --> 00:03:56.200
Welt. Und das liegt hauptsÃ¤chlich daran, dass man im Internet alles automatisieren kann,

00:03:56.680 --> 00:04:02.000
also insbesondere natÃ¼rlich Datensammlung kann man automatisieren, automatische Interferenz,

00:04:02.000 --> 00:04:07.360
Data-Mining, schnelle Suche, man kann groÃŸe DatenbestÃ¤nde schnell verknÃ¼pfen, hat entsprechende

00:04:07.360 --> 00:04:14.040
Ãœberwachungstechnik im Internet. Und der zweite Grund ist, dass Vertraulichkeit basiert ja immer

00:04:14.040 --> 00:04:21.080
darauf, dass Leute irgendwas sehen, was vielleicht nicht fÃ¼r sie bestimmt war. Und Vertraulichkeit,

00:04:21.080 --> 00:04:26.000
die Verlust von Vertraulichkeit hat man frÃ¼her oft dadurch festgestellt, dass etwas gefehlt

00:04:26.200 --> 00:04:31.680
hat. Also ein Buch hat gefehlt oder ein Dokument hat gefehlt. Bei digitalen Dokumenten, da kann man

00:04:31.680 --> 00:04:35.360
die kann man stehlen, ohne dass man merkt, dass sie gestohlen worden sind, weil man einfach

00:04:35.360 --> 00:04:40.400
eine Kopie macht. Das heiÃŸt also auch die Kopierbarkeit, die einfache Kopierbarkeit

00:04:40.400 --> 00:04:48.280
von Daten katalysiert auch den Verlust an Vertraulichkeit und dann natÃ¼rlich auch AnonymitÃ¤t.

00:04:48.280 --> 00:04:55.280
Und heutzutage, es gibt nÃ¤mlich eine Replik auf diesen New Yorker-Kartun, heutzutage sieht

00:04:55.280 --> 00:05:00.680
er so aus, das ist von 2010, wieder zwei Hunde und da eine sagt, how the hell does Facebook know

00:05:00.680 --> 00:05:10.440
I'm a dog? Das drÃ¼ckt im Prinzip die um 180 Grad geÃ¤nderte Auffassung des Internet aus. Und um

00:05:10.440 --> 00:05:15.560
diese Aspekte soll es heute gehen in der Veranstaltung. Wir betrachten die Vertraulichkeit

00:05:15.560 --> 00:05:22.240
von personenbezogenen Daten, also im Prinzip das, was man Privatheit nennt, personenbezogene Daten

00:05:22.240 --> 00:05:28.200
und den Schutz von personenbezogenen Daten. Und das ist ein Thema, was natÃ¼rlich, brauche ich

00:05:28.200 --> 00:05:33.320
nicht zu erzÃ¤hlen, Ã¼ber die letzten Jahrzehnte auch ein relevantes gesellschaftliches Thema ist.

00:05:33.320 --> 00:05:40.600
Ich gehe mal so ein bisschen zurÃ¼ck aus der aktuellen Zeit. Es gab und zeigt ein paar Dokumente,

00:05:40.600 --> 00:05:46.200
die vielleicht auch charakteristisch sind fÃ¼r DiskussionsstrÃ¶me zu entsprechenden Zeiten in

00:05:46.200 --> 00:05:52.640
der Vergangenheit. Das ist von Christopher Wiley das Buch, weiÃŸ nicht, ob man das

00:05:52.640 --> 00:05:59.640
aussprechen kann, aussprechen darf, auf Tone Mind. BEEP, fuck Cambridge Analytica and the Plot to

00:05:59.640 --> 00:06:09.400
Break America. Da geht es um die Beeinflussung von der Firma Cambridge Analytica, oder die

00:06:09.400 --> 00:06:16.480
potenzielle Beeinflussung der Firma Cambridge Analytica auf die US-Wahl 2019. Und das war damals

00:06:16.480 --> 00:06:22.800
auch groÃŸ in den Medien. Das Problem war, dass halt Facebook Daten ungeschÃ¼tzt online zur

00:06:22.800 --> 00:06:26.600
VerfÃ¼gung gestellt hatte. Die konnten also massenweise Facebook-Daten abziehen und hatten

00:06:26.600 --> 00:06:33.280
da die MÃ¶glichkeit natÃ¼rlich dann gezielt Leute gemÃ¤ss ihren PrÃ¤ferenzen anzusprechen. Und wenn

00:06:33.280 --> 00:06:38.000
man das Buch liest, also Christopher Wiley war einer von den Leuten, die bei Cambridge Analytica

00:06:38.000 --> 00:06:44.160
gemacht haben, da wird einem teilweise auch so Angst und Bange, wenn man liest, wie sich ein

00:06:44.160 --> 00:06:50.160
SpaÃŸ draus gemacht haben, einzelne DatensÃ¤tze da rauszuziehen und die Leute anzurufen und zu

00:06:50.160 --> 00:06:55.440
pranken, also den irgendwie vorzumachen, sie wÃ¤ren unter Versicherung und die irgendwie vorzufÃ¼hren

00:06:55.440 --> 00:07:00.440
oder so. Also da wird es einem ganz anders. Aber das kann man natÃ¼rlich machen, wenn man entsprechende

00:07:00.440 --> 00:07:08.400
Daten hat. Dass diese Daten bei privaten Firmen vorrÃ¤tig sind, das weiÃŸ man. Das weiÃŸ man heute

00:07:08.400 --> 00:07:12.920
natÃ¼rlich, wusste man vielleicht auch schon frÃ¼her. Google und Facebook waren ja schon immer in der

00:07:12.920 --> 00:07:19.280
Kritik. Aber dass diese Daten natÃ¼rlich auch im Besitz von staatlichen BehÃ¶rden sind, auch

00:07:19.280 --> 00:07:27.400
Nachrichtendiensten, das weiÃŸ man seit 2015 bzw. 2013 als Edward Snowden, die die NSA-Leaks

00:07:27.400 --> 00:07:33.640
herausgebracht hat und Glenn Greenwald darÃ¼ber dann berichtet hat in der Zeitung natÃ¼rlich und

00:07:33.640 --> 00:07:38.680
auch dieses Buch geschrieben hat, das sehr empfehlenswert ist. Seitdem weiÃŸ man, dass es

00:07:38.680 --> 00:07:45.720
auch nicht unwahrscheinlich ist, dass auch staatliche BehÃ¶rden halt sehr, sehr tiefen Einblick

00:07:45.720 --> 00:07:55.040
darin haben, was man privat macht. In der Zeit war das auch so, dass die GeschÃ¤ftsmodelle von

00:07:55.080 --> 00:08:00.760
Google, Facebook und anderen auch tatsÃ¤chlich hinterfragt worden sind. Es ist vielleicht auch

00:08:00.760 --> 00:08:06.840
nur eine Diskussion, die Sie sich erinnern vor zehn Jahren. Da kam von Jaron Lanier dieses Buch

00:08:06.840 --> 00:08:15.200
aus Who Owns the Future. Jaron Lanier, ein bekannter Technikphilosoph aus den Vereinigten

00:08:15.200 --> 00:08:20.120
Staaten, der fÃ¼r dieses Buch auch den Friedenspreis des deutschen Buchhandels gekriegt hat. Da geht es

00:08:20.120 --> 00:08:26.000
auch darum, diese GeschÃ¤ftsmodelle erstmal zu verstehen. Er hat damals auch den Begriff

00:08:26.000 --> 00:08:32.880
geprÃ¤gt, dass im Prinzip, wenn man diese kostenlose Dienste von Google, Facebook und so weiter benutzt,

00:08:32.880 --> 00:08:38.120
dass man denkt, okay, das ist kostenlos, also habe ich ja nichts zu verlieren, wenn ich die benutze,

00:08:38.120 --> 00:08:42.520
kostet ja nichts. Aber heutzutage weiÃŸ man natÃ¼rlich, dass man mit seinen eigenen Daten

00:08:42.520 --> 00:08:49.560
bezahlt. Jaron Lanier hat damals diesen Begriff oder diesen Hausdruck geprÃ¤gt. You are the

00:08:49.560 --> 00:08:56.880
product, not the customer von diesen Diensten. Und das trifft, glaube ich, relativ gut, was mit

00:08:56.880 --> 00:09:03.560
Ihnen und Ihren Daten da passiert. Das ist im Prinzip auch schon lange da gewesen. Ich kann

00:09:03.560 --> 00:09:08.400
mich noch erinnern an die Anfangszeit vom Internet, wo auch Google hochkam und Google hatte ja damals

00:09:08.400 --> 00:09:18.400
das Motto, do no evil oder so was, also mÃ¶glichst positiv auf die Welt zu wirken. Aber auch so

00:09:18.400 --> 00:09:24.800
Anfang der Nuda Jahre oder in den Nuda Jahren kam dann, wurde dann auch so, als Google angefangen

00:09:24.800 --> 00:09:29.560
hat, ein kommerzielles GeschÃ¤ftsmodell anzuwenden und zu gucken, wie man mit den Daten, die sie

00:09:29.560 --> 00:09:34.600
sammeln, Geld verdienen kann. Da kam Google immer mehr in Kritik, in die Kritik und das ist mal hier

00:09:34.600 --> 00:09:41.200
so von 2011, ein Tiertelbild im Spiegel. Da kam auch sozusagen der Umschwung in der Ã¶ffentlichen

00:09:41.200 --> 00:09:48.160
Meinung von den positiven Weltverbesserern zu den unersÃ¤ttlichen, wie man hier sagt. Also kam

00:09:48.320 --> 00:09:56.840
auch die negativen Aspekte hoch, die von der Datensammelwut der Internetkonzerne entspringt.

00:09:56.840 --> 00:10:03.320
Und das finde ich immer noch ein sehr schÃ¶nes Bild, wo man sieht, wie die Leute hier aus den

00:10:03.320 --> 00:10:09.480
HochhÃ¤usern diese komische Krake da anschauen, die mit ihrer Kamera vorne ausgestattet ist. Und

00:10:09.560 --> 00:10:18.760
man sieht, die springen aus den Fenstern auf diese Krake drauf. Also sehr schÃ¶ne Metapher dafÃ¼r,

00:10:18.760 --> 00:10:25.520
dass man im Prinzip freiwillig sich in die FÃ¤nge dieser Konzerne begibt. Gibt es eine

00:10:25.520 --> 00:10:26.280
Meldung ganz hinten?

00:10:39.480 --> 00:10:51.360
Das kann gut sein, dass da noch eine Referenz drinne steckt. Das ist gut beobachtet. Vielleicht

00:10:51.360 --> 00:10:55.120
kÃ¶nnen Sie mir noch mal eine Referenz schicken auf oder ins Forum posten, dann kann ich das noch

00:10:55.120 --> 00:11:00.920
in den Unterlagen mit aufnehmen. Oder ich schreibe es mir auf. Ich habe jetzt gerade nichts zum

00:11:00.920 --> 00:11:06.320
Schreiben dabei. Vielleicht schicken Sie mir einfach noch eine E-Mail. Danke. Das ist aber

00:11:06.400 --> 00:11:11.120
der Anfang der Diskussion gewesen. In den kritischen Informatikkreisen gibt es ja schon

00:11:11.120 --> 00:11:20.920
seit den 80ern die Diskussion in den Vereinigten Staaten wie in Deutschland. Und ein Ausdruck dieser

00:11:20.920 --> 00:11:26.640
kritischen Diskussion ist dieses Buch von Simpson Garfinkel, das 2001 erschienen ist,

00:11:26.640 --> 00:11:35.880
also vor fast 25 Jahren, das viele plastische Beispiele enthÃ¤lt fÃ¼r was aus mangelndem

00:11:35.880 --> 00:11:40.400
Datenschutz passieren kann. Und ein paar von den Beispielen bringe ich auch nachher noch in

00:11:40.400 --> 00:11:48.800
der Vorlesung. Und alles geht im Prinzip zurÃ¼ck auf Diskussionen, die schon eigentlich in den

00:11:48.800 --> 00:11:53.800
80er Jahren, in den 1980er Jahren, in den 80er Jahren des letzten Jahrhunderts gefÃ¼hrt worden

00:11:53.800 --> 00:12:00.000
sind und die in Ursprungnahmen in einem Gerichtsurteil, was 1983 ergangen ist,

00:12:00.000 --> 00:12:05.280
durch das Bundesverfassungsgericht, jedenfalls die deutsche Diskussion, das Urteil trÃ¤gt das Datum

00:12:05.680 --> 00:12:12.640
15. Dezember 1983. Und das ist das sogenannte VolkszÃ¤hlungsurteil des Bundesverfassungsgerichts.

00:12:12.640 --> 00:12:19.480
Und in diesem Urteil ist ein neues Grundrecht entwickelt worden. Es gibt ja die verschiedenen

00:12:19.480 --> 00:12:24.440
Grundrechte, die in der Verfassung fixiert sind. Aber Grundrechte kÃ¶nnen auch sozusagen neu

00:12:24.440 --> 00:12:30.240
entwickelt werden durch das Verfassungsgericht, aus den anderen Grundrechten abgeleitet. Und dort

00:12:30.240 --> 00:12:34.600
entwickeln sie das Grundrecht auf informationelle Selbstbestimmung. Und informationelle

00:12:34.600 --> 00:12:41.480
Selbstbestimmung, das ist im Prinzip ein Grundrecht, was den Schutz des einzelnen

00:12:41.480 --> 00:12:46.200
Ausdrucks gegen unbegrenzte Erhebung, Speicherung, Verwendung und Weitergabe seiner persÃ¶nlichen

00:12:46.200 --> 00:12:53.040
Daten. In dem Urteil geht es im Wesentlichen Ã¼ber die staatliche Verarbeitung von Daten,

00:12:53.040 --> 00:12:59.640
weil da war die VolkszÃ¤hlung, da gab es einen Riesenaufstand damals. Wenn man heute schaut,

00:12:59.640 --> 00:13:03.400
was da an Daten erhoben worden sind und von wem ist es eigentlich lÃ¤cherlich. Also es gab ja

00:13:03.560 --> 00:13:10.440
vor kurzem diesen Zensus, den alle vÃ¶llig kritiklos mitgemacht haben. Aber das war

00:13:10.440 --> 00:13:16.720
damals sozusagen der Ausgangspunkt fÃ¼r dieses neue Grundrecht. Und was wir heute in der Vorlesung

00:13:16.720 --> 00:13:25.360
machen, das neben diesem geschichtlichen RÃ¼ckblick, schauen wir uns mal an, wie es zu

00:13:25.360 --> 00:13:30.840
diesem Grundrecht kam und warum vor allem dieses Grundrecht existiert. Und da geht es auch erstmal

00:13:30.960 --> 00:13:37.400
um Begriffe natÃ¼rlich. Es geht um Privatheit, Vertraulichkeit, ist die Frage, was ist eigentlich

00:13:37.400 --> 00:13:44.760
der Unterschied. Und begrifflich ist es so, dass es auch in der englischen Literatur diesen

00:13:44.760 --> 00:13:50.400
Unterschied gibt zwischen Secrecy, Confidentiality und Privacy. Confidentiality ist dieses

00:13:50.400 --> 00:13:54.920
Sicherheitsziel der Vertraulichkeit, was wir schon mal, was wir ganz am Anfang kennengelernt

00:13:54.920 --> 00:14:01.080
haben. Und eigentlich das Grundprinzip, was hinter beidem steckt, ist, dass etwas geheim ist,

00:14:01.080 --> 00:14:09.680
Secret ist. Also gemÃ¤ÃŸ den Definition von Gollmann, the effect of mechanisms that used to limit the

00:14:09.680 --> 00:14:14.240
number of principles who can access information. Also das im Prinzip, dass etwas geheim ist,

00:14:14.240 --> 00:14:20.080
also dass eine eingeschrÃ¤nkte Personenzahl etwas weiÃŸ. Wenn man jetzt von Confidentiality oder

00:14:20.080 --> 00:14:24.160
Vertraulichkeit spricht, das transportiert immer so ein bisschen mit die Erwartung,

00:14:24.160 --> 00:14:30.760
dass etwas geheim bleibt. Also Secrecy ist die Tatsache, dass es geheim ist und Confidentiality

00:14:30.760 --> 00:14:35.920
auch die Erwartung, dass etwas geheim ist oder geheim bleibt, also deutsch vertraulich bleibt.

00:14:35.920 --> 00:14:44.040
Da gibt es aber auch noch Privacy oder Privatheit, dass etwas privat bleibt. Das bezieht sich im

00:14:44.040 --> 00:14:49.320
Prinzip auf das Recht oder die FÃ¤higkeit bestimmter Daten, nÃ¤mlich personenbezogene,

00:14:49.320 --> 00:14:56.520
persÃ¶nliche Daten geheim zu halten, also vertraulich zu halten. Also Privacy oder

00:14:56.520 --> 00:15:01.560
Privatheit bezieht sich immer auf irgendwas, was Individuen angeht. Privatheit ist etwas,

00:15:01.560 --> 00:15:06.720
was also Firmen haben keine PrivatsphÃ¤re, wenn man so will, aber Personen haben PrivatsphÃ¤re.

00:15:06.720 --> 00:15:14.720
Gut, PrivatsphÃ¤re ist natÃ¼rlich ein Begriff, der auch in der Literatur, auch in der Vergangenheit,

00:15:14.720 --> 00:15:19.880
in der Philosophie usw. auch schon viel betrachtet worden ist. PrivatsphÃ¤re ist im Prinzip ein

00:15:20.920 --> 00:15:35.720
Konzept, was es erlaubt, dass man persÃ¶nliche VorgÃ¤nge nicht Ã¶ffentlich teilen muss. In der

00:15:35.720 --> 00:15:40.720
Literatur wird das oft unterschiedlich charakterisiert. Es gibt von Louis Brandeis

00:15:40.720 --> 00:15:47.400
in einem Artikel von 1890 eine Definition, die sagt, das ist the individual's right to be left

00:15:47.400 --> 00:15:55.120
alone, also dass man einfach alleine bleibt und sich nicht mit anderen auseinandersetzen muss. Aber

00:15:55.120 --> 00:15:59.440
im Prinzip ist das einfach die Sicherheit, dass es so einen nicht Ã¶ffentlichen Bereich gibt,

00:15:59.440 --> 00:16:07.960
in dem ein Mensch unbehelligt die eigene PersÃ¶nlichkeit entfalten kann. Und wenn man

00:16:07.960 --> 00:16:17.080
das Buch von Glenn Greenwald Ã¼ber die Snowden Leaks liest, der zweite Teil dieses Buches ist

00:16:17.080 --> 00:16:23.440
im Prinzip eine Legitimation von Privatheit. Also eine flammende Rede, dass es doch wichtig ist,

00:16:23.440 --> 00:16:29.320
PrivatsphÃ¤re zu haben und dass auch Gesellschaften PrivatsphÃ¤re als Grundrecht zu schÃ¼tzen haben,

00:16:29.320 --> 00:16:35.000
weil PrivatsphÃ¤re ein ganz ganz zentraler Mechanismus der gesellschaftlichen Erneuerung

00:16:35.000 --> 00:16:38.440
und Innovation ist. Also nicht nur der gesellschaftlichen Erneuerung, sondern auch

00:16:38.440 --> 00:16:43.080
der der Innovation einer Gesellschaft. Das ist nicht nur gesellschaftliche Strukturen,

00:16:43.080 --> 00:16:48.320
sondern auch natÃ¼rlich wirtschaftliche Strukturen. Also dass freiheitliche Gesellschaften nicht nur

00:16:48.320 --> 00:16:53.280
besser sind, was die PersÃ¶nlichkeitsentwicklung angeht, sondern auch was auch die Menschheitsentwicklung

00:16:53.280 --> 00:16:59.880
angeht. Wenn man den Klimawandel und so anschaut, dann kann man daran natÃ¼rlich auch zweifeln,

00:16:59.880 --> 00:17:04.600
aber ob das jetzt ein alleiniger Grund von freiheitlichen Gesellschaften ist, ist wieder

00:17:04.600 --> 00:17:13.480
die andere Frage. PrivatsphÃ¤re hat in der Literatur immer so drei verschiedene Dimensionen. So die

00:17:13.480 --> 00:17:18.320
ersten zwei, das ist so die personenbezogene PrivatsphÃ¤re. Das ist so das Grundrecht,

00:17:18.320 --> 00:17:24.520
dass der eigene KÃ¶rper unbeeinflusst oder unbehelligt von unzulÃ¤ssiger Einflussnahme

00:17:24.520 --> 00:17:30.400
bleibt. Also zum Beispiel KÃ¶rperdurchsuchung, also eine Durchsuchung, eine Personendurchsuchung

00:17:30.400 --> 00:17:35.720
oder sowas ist verstÃ¶ÃŸt gegen das Grundrecht der personenbetrogenen PrivatsphÃ¤re. Aber es

00:17:35.720 --> 00:17:40.320
gibt auch die rÃ¤umlich PrivatsphÃ¤re, das ist im Prinzip der Schutz der eigenen vier WÃ¤nde,

00:17:40.320 --> 00:17:49.640
wenn man so will, des eigenen Hauses, dass da nicht ohne Grund eingegriffen werden kann. Und wie

00:17:49.640 --> 00:17:57.160
gesagt 1983 entwickelt die informationelle PrivatsphÃ¤re, der Schutz davor, dass andere

00:17:57.160 --> 00:18:05.200
Leute beliebig Ã¼ber einen selbst Daten sammeln kÃ¶nnen und die weitergeben kÃ¶nnen. In diesem

00:18:05.200 --> 00:18:08.720
dritten Teil mit der personenbetrogenen, mit der informationellen PrivatsphÃ¤re, da steckt

00:18:08.720 --> 00:18:16.040
natÃ¼rlich dieser Datenschutz, dieser Datenschutz oder dieses Konzept von Datenschutz drinne und

00:18:16.040 --> 00:18:23.480
da mÃ¼ssen wir kurz drÃ¼ber sprechen, was das eigentlich bedeutet. Also hier steckt immer

00:18:23.600 --> 00:18:31.160
so ein bisschen der Begriff, oder da steckt das Konzept drin, dass es Daten gibt, die fÃ¼r einen

00:18:31.160 --> 00:18:35.680
selber irgendwie relevanter sind, weil es Daten sind, die einen selber betreffen,

00:18:35.680 --> 00:18:41.760
persÃ¶nlichen Informationen hier. Und da gibt es diesen Begriff, der auch im Datenschutzrecht

00:18:41.760 --> 00:18:46.120
geprÃ¤gt ist, das sind personenbezogene Daten. Personenbezogene Daten ist zunÃ¤chst mal ein

00:18:46.120 --> 00:18:52.960
rechtlicher Begriff. Personenbezogene Daten sind durch den Datenschutz sozusagen durch das Recht

00:18:52.960 --> 00:18:59.120
geschÃ¼tzt. Wenn man in die Literatur reinschaut, insbesondere in die rechtliche Literatur, dann

00:18:59.120 --> 00:19:04.080
steht da drinne, Daten sind personenbezogen, wenn sie eindeutig einer bestimmten, natÃ¼rlichen

00:19:04.080 --> 00:19:09.240
Person zugeordnet sind. Also das heiÃŸt der Name, die Adresse zum Beispiel oder ihre Matrikelnummer.

00:19:09.240 --> 00:19:15.920
Oder diese Zuordnung zumindest mittelbar erfolgen kann. Also auch ein Datensatz,

00:19:15.920 --> 00:19:19.440
der sie betrifft und der ihnen irgendwie mit etwas Aufwand zugeordnet werden kann,

00:19:19.440 --> 00:19:26.320
das sind auch personenbezogene Daten. Jetzt steckt da natÃ¼rlich, hier vielleicht ist es

00:19:26.320 --> 00:19:30.240
eindeutiger bei dem ersten Punkt wie bei dem zweiten Punkt, das ist immer die Frage,

00:19:30.240 --> 00:19:35.720
wie viel Aufwand muss man denn treiben, damit Daten personenbezogen sind. Also im Prinzip gibt

00:19:35.720 --> 00:19:43.320
es da die Diskussion, ja es gibt im Prinzip die Diskussion auch von den Datenschutzpuristen,

00:19:43.400 --> 00:19:49.800
die sagen, im Prinzip gibt es keine nicht personenbezogenen Daten. Selbst wenn ich in

00:19:49.800 --> 00:19:58.120
der Antarktis eine Wetterstation habe, die Wetterdaten sammelt, wenn ich die verknÃ¼pfe mit zum

00:19:58.120 --> 00:20:05.120
Beispiel den EinsatzplÃ¤nen der Techniker, die diese Wetterstation warten oder sowas,

00:20:05.120 --> 00:20:10.080
dann ist die Tatsache, dass da was gemessen wird, zum Beispiel auch ein personenbezogenes Datum.

00:20:10.160 --> 00:20:14.560
Das Ding ist repariert worden zu einer bestimmten Zeit von einer bestimmten Person. Mit den

00:20:14.560 --> 00:20:19.560
entsprechenden flankierenden Daten kann man alles personenbezogen machen, so argumentieren die

00:20:19.560 --> 00:20:26.840
Puristen. Aber das ist natÃ¼rlich eher so eine informatische Diskussion, die Rechtswissenschaftler

00:20:26.840 --> 00:20:31.440
wÃ¼rden dann sagen, okay das ist ja abwegig. Aber natÃ¼rlich kÃ¶nnen die Rechtswissenschaftler auch

00:20:31.440 --> 00:20:36.560
nicht sagen, wie viel Aufwand denn exakt notwendig ist, damit etwas personenbezogen ist oder nicht.

00:20:36.560 --> 00:20:41.680
Das ist immer eine EinzelfallabschÃ¤tzung. Und das fÃ¼hrt auch zu der Beobachtung,

00:20:41.680 --> 00:20:47.840
dass wenn sie jetzt Daten haben, die nicht personenbezogen sind oder die von Gerichten

00:20:47.840 --> 00:20:51.920
vielleicht auch nicht als personenbezogen eingeschÃ¤tzt werden, dass sie nÃ¤chstes Jahr

00:20:51.920 --> 00:20:58.520
oder morgen schon personenbezogen sein kÃ¶nnten, weil vielleicht Daten liegen, wenn man die verknÃ¼pft

00:20:58.520 --> 00:21:03.400
mit den Daten, die plÃ¶tzlich personenbezogen machen. Oder dass es irgendwelche Techniken gibt,

00:21:03.880 --> 00:21:09.840
die nÃ¤chstes Jahr schon irgendwie es erlauben, bestimmte Daten mit anderen DatenbestÃ¤nden zu

00:21:09.840 --> 00:21:14.600
verknÃ¼pfen und zu deanalyseieren. Das heiÃŸt, was man eigentlich braucht, ist immer so eine Art

00:21:14.600 --> 00:21:22.160
DatenschutzfolgenabschÃ¤tzung. Das heiÃŸt, wenn man Daten publizieren mÃ¶chte, dann muss man mal sagen,

00:21:22.160 --> 00:21:27.680
wie hoch ist das Risiko jetzt, dass sie personenbezogen werden und wie groÃŸ ist

00:21:27.760 --> 00:21:36.000
das Risiko, dass sie in Zukunft personenbezogen sein kÃ¶nnen. Also personenbezogene Daten machen

00:21:36.000 --> 00:21:41.680
im Prinzip viel von der eigenen IdentitÃ¤t aus. Wir hatten Ã¼ber IdentitÃ¤t auch kurz mal gesprochen

00:21:41.680 --> 00:21:47.080
in dem Kapitel Ã¼ber Authentifikation. Also im Prinzip, wenn man jetzt eine digitale IdentitÃ¤t

00:21:47.080 --> 00:21:53.880
anschaut, also wie IdentitÃ¤t in der digitalen Welt reprÃ¤sentiert ist, dann ist es im Prinzip die

00:21:53.880 --> 00:21:59.920
Sammlung der personenbezogenen Daten, die es Ã¼ber einen selber gibt. Also entweder die, die

00:21:59.920 --> 00:22:05.000
alle schon da sind oder die da sein kÃ¶nnten. Das ist hier mal in der Grafik dargestellt. Also das

00:22:05.000 --> 00:22:10.640
ist hier die digitale IdentitÃ¤t. Im Prinzip alle Daten, die es Ã¼ber sie geben kÃ¶nnte und die

00:22:10.640 --> 00:22:15.200
irgendwo online gespeichert werden kÃ¶nnten. Das sind dann zum Beispiel ihr Name, Geburtstag,

00:22:15.200 --> 00:22:21.240
Alter, Adresse und so weiter. Klar, personenbezogen, Telefonnummer, Blutgruppe, also biologische Aspekte,

00:22:21.240 --> 00:22:27.000
Steuerklasse, ihr Tagebuch zum Beispiel. Das ist nirgendwo hoffentlich bei jemand anders gespeichert,

00:22:27.000 --> 00:22:38.040
sondern nur bei Ihnen. Und es gibt verschiedene Organisationen oder EntitÃ¤ten, die Teile ihrer

00:22:38.040 --> 00:22:43.120
IdentitÃ¤t kennen und auch notwendigerweise. Das heiÃŸt also eine Bank braucht zum Beispiel von

00:22:43.120 --> 00:22:52.040
Ihnen Name, Adresse, Alter, also Geburtstag. Damit Sie Ihr Alter exakt bestimmen kÃ¶nnen. Wenn Sie

00:22:52.040 --> 00:22:57.600
ein Konto erÃ¶ffnen, mÃ¼ssen Sie mindestens 18 sein. Telefonnummer, Kreditrisiko und so weiter,

00:22:57.600 --> 00:23:01.280
das speichert die Bank Ã¼ber Sie und auch notwendigerweise. Aber die haben halt nicht

00:23:01.280 --> 00:23:06.400
ihre Blutgruppe, ihre Steuerklasse vielleicht, vielleicht auch nicht, aber vielleicht auch

00:23:06.400 --> 00:23:12.800
nicht ihre Interessen oder sowas. Und verschiedene Akteure haben halt unterschiedliche Teile,

00:23:12.880 --> 00:23:20.360
ihre IdentitÃ¤t, das nennt man dann digitale TeilidentitÃ¤ten. Und die Gefahr ist natÃ¼rlich,

00:23:20.360 --> 00:23:24.880
dass wenn sich verschiedene von diesen Akteuren zusammentun, dass sie dann sozusagen ihre

00:23:24.880 --> 00:23:30.560
vollstÃ¤ndige IdentitÃ¤t oder einen groÃŸen Teil ihrer digitalen IdentitÃ¤t dann zusammenlegen kÃ¶nnen

00:23:30.560 --> 00:23:40.320
und im Prinzip zusammen mehr Ã¼ber sie wissen als jeweils einzeln. Der Grad des Personenbezugs

00:23:40.360 --> 00:23:44.520
von verschiedenen Daten, das war auch unterschiedlich. Und entsprechend unterschiedlich

00:23:44.520 --> 00:23:50.760
sind die Daten dann einzuschÃ¤tzen bezÃ¼glich der ihre Gefahren fÃ¼r die PrivatsphÃ¤re oder

00:23:50.760 --> 00:23:55.720
die Relevanz von Daten fÃ¼r die PrivatsphÃ¤re. Und da gibt es auch im Datenschutz, in der

00:23:55.720 --> 00:24:02.440
Datenschutzdiskussion so unterschiedliche Eigenschaften, auf die man schaut, wenn es

00:24:02.440 --> 00:24:07.440
darum geht eine DatenschutzeinschÃ¤tzung zu machen. Sind Daten personenbezogen oder nicht oder sind

00:24:07.520 --> 00:24:12.360
die relevant fÃ¼r die PrivatsphÃ¤re oder nicht, wenn man also so eine EinschÃ¤tzung machen mÃ¶chte.

00:24:12.360 --> 00:24:17.360
Also weniger relevant sind sie dann, wenn sie anonym sind, also nicht direkt zuortenbar,

00:24:17.360 --> 00:24:23.320
wenn die sich Ã¤ndern, ohne dass man das von nach auÃŸen mitkriegt, wenn die flÃ¼chtig sind,

00:24:23.320 --> 00:24:28.000
also wenn sie schnell sich Ã¤ndern, wenn sie nur einmal verwendet werden und wenn sie im Prinzip

00:24:28.000 --> 00:24:34.800
so Ã¤hnlich sind wie die Eigenschaften, die alle anderen auch haben. Relevanter sind natÃ¼rlich

00:24:34.960 --> 00:24:41.120
Daten, die sie eindeutig identifizieren, die unverÃ¤nderlich sind, die langfristig

00:24:41.120 --> 00:24:53.280
gespeichert werden, die anderen zugreifbar sind, die sie hÃ¤ufig verwenden und die unnormal und

00:24:53.280 --> 00:25:03.680
herausragend sind. Genau. Und wenn jetzt solche Daten oder Datenmengen dann in die Hand von

00:25:03.680 --> 00:25:10.720
vielleicht bÃ¶sartigen Gegenspielern kommen, dann gibt es natÃ¼rlich Bedrohungen fÃ¼r die PrivatsphÃ¤re

00:25:10.720 --> 00:25:15.520
und ich will die mal ganz kurz erlÃ¤utern an ein paar Beispielen. Im Prinzip auch Sachen,

00:25:15.520 --> 00:25:19.040
die aus Database Nation kommen, also zum Beispiel Fehlentscheidungen durch Falschinformationen,

00:25:19.760 --> 00:25:24.920
also wenn zum Beispiel falsche Daten Ã¼ber sie irgendwo gespeichert sind und sie keine

00:25:24.920 --> 00:25:29.960
MÃ¶glichkeit haben, die zu korrigieren, dann kann das zu Problemen fÃ¼hren. Also das Beispiel aus

00:25:29.960 --> 00:25:36.160
Database Nation ist, in den Vereinigten Staaten ist der Datenschutz etwas weniger ausgeprÃ¤gt als in

00:25:36.160 --> 00:25:43.880
Europa und da ist es normal, dass Banken das Kreditrisiko von ihren Kunden einschÃ¤tzen und

00:25:43.880 --> 00:25:48.040
diese Daten auch miteinander austauschen. Im Prinzip so eine Art Peer-to-Peer-Schufa,

00:25:48.040 --> 00:25:54.800
wenn man so will. Das Problem ist, dass man als Privatperson relativ wenig Einfluss darauf hat,

00:25:54.800 --> 00:26:01.520
wie diese Daten zirkulieren. Das heiÃŸt, wenn Sie in den Vereinigten Staaten zum Beispiel in diesen

00:26:01.520 --> 00:26:06.680
Daten, in deren fehlerhafter Eintrag ist, dass Sie zum Beispiel Ihre Kredite nicht bezahlen und diese

00:26:06.680 --> 00:26:12.320
Daten falsch sind, dann kÃ¶nnen Sie sich durch bei der Bank, bei der Sie einen Kredit haben wollen,

00:26:12.320 --> 00:26:17.360
sich beschweren und so weiter. Okay, dann kann die das korrigieren, aber diese Daten sind ja im

00:26:17.360 --> 00:26:21.760
Umlauf, sind schon ausgetauscht worden und irgendwann kommen die wieder zurÃ¼ck zu ihrer Bank, ohne dass

00:26:21.760 --> 00:26:25.880
klar ist, wo das herkommt und plÃ¶tzlich ist ihr Kreditrisiko wieder weg und dann dÃ¼rfen Sie nicht

00:26:25.880 --> 00:26:33.320
mehr mit Ihrer Kreditkarte einkaufen. Da gibt es ganz viele ganz viele Beispiele fÃ¼r sowas. Also

00:26:33.320 --> 00:26:37.760
auch zum Beispiel in Deutschland ist es falsches Schufa-EintrÃ¤ge. Also ich weiÃŸ nicht, wer von Ihnen

00:26:37.760 --> 00:26:42.960
hat seinen Schufa-Eintrag schon mal abgefragt. Ich glaube, ein oder zweimal pro Jahr ist das

00:26:42.960 --> 00:26:49.400
kostenlos mÃ¶glich. Schauen Sie mal rein, da sehen Sie nÃ¤mlich drinnen, was da fÃ¼r EintrÃ¤ge sind und

00:26:49.400 --> 00:26:58.320
wer ihre KreditwÃ¼rdigkeit abgefragt hat. Also durchaus sehr interessant. Langfristig Aufbewahrung

00:26:58.320 --> 00:27:05.240
ist auch ein Problem. Alle Leute, die als Kind oder als Jugendliche, als Kind Facebook-Account hatten

00:27:05.240 --> 00:27:10.040
und da tolle Fotos von sich gepostet haben in allen mÃ¶glichen Situationen, die Ã¤rgern sich vielleicht

00:27:10.040 --> 00:27:14.800
spÃ¤ter, wenn sie sich bewerben, dass diese Informationen da noch sind aus der Schule zum

00:27:14.800 --> 00:27:22.800
Beispiel. Das heiÃŸt, im Prinzip ist eine langfristige Aufbewahrung auch nicht gut fÃ¼r die PrivatsphÃ¤re,

00:27:22.800 --> 00:27:30.440
wenn man nicht die ganze Zeit irgendwie hÃ¶llisch drauf achtet, was man selber gepostet hat zum

00:27:30.440 --> 00:27:39.440
Beispiel. Und so werden natÃ¼rlich auch die Handlungen, die sie frÃ¼her mal gemacht haben,

00:27:39.440 --> 00:27:49.520
sehr viel einfacher rekonstruierbar. Und das ist die Daten, die man teilweise aus den sogenannten,

00:27:49.520 --> 00:28:01.120
bisschen mehr Ruhe bitte, ich hÃ¶re das getuscht Ã¼berall jetzt. Da zum Beispiel, da, vielen Dank.

00:28:01.120 --> 00:28:12.840
Was wollte ich jetzt eigentlich erzÃ¤hlen? Ah ja, genau, dass die Daten, die Ã¼ber sie gespeichert

00:28:12.840 --> 00:28:17.960
sind, da viel detaillierter sind als ihre eigenen Erinnerungen. Also es gibt ja diesen Begriff der

00:28:17.960 --> 00:28:23.840
Open Source Intelligence, also auch Sachen, die sie Ã¼ber quelloffene Software einsehen kÃ¶nnen.

00:28:23.840 --> 00:28:28.680
Wenn irgendwann Ã¼ber sie mal ein Zeitungsartikel erschienen ist, ist er auch auf Ewigkeit irgendwie

00:28:28.680 --> 00:28:34.400
auffindbar. Und da kann man relativ viel Ã¼ber Leute rauskriegen und zwar viel besser und

00:28:34.400 --> 00:28:39.800
detaillierter als an, was sich die Leute teilweise selber noch erinnern kÃ¶nnen. Das ist sogar,

00:28:39.800 --> 00:28:45.360
wÃ¼rde ich mal sagen, besser als die Stasi-Akten und die sind ja schon relativ detailliert, egal,

00:28:45.360 --> 00:28:51.440
was da drinne steht. So was auch geht, ist IdentitÃ¤tstiefstahl. Das ist vielleicht auch

00:28:51.440 --> 00:28:57.080
dem anderen von Ihnen ein Begriff. Das ist im Prinzip die illegitime Nutzung einer anderen

00:28:57.080 --> 00:29:04.680
IdentitÃ¤t, um zum Beispiel irgendwas zu bestellen. Zum Beispiel, also eine Form von Betrug natÃ¼rlich.

00:29:04.680 --> 00:29:13.280
Da gibt es die Masche, dass man zum Beispiel einen Account Ã¼bernimmt, einen Amazon-Account

00:29:13.280 --> 00:29:19.520
oder einen Facebook-Account von jemandem, plÃ¶tzlich funktioniert ihr Passwort nicht mehr und Ã¼ber ihr

00:29:19.520 --> 00:29:27.120
Facebook-Account wird ganz viel Propaganda zum Beispiel oder Ã¼ber ihren Twitter-Account,

00:29:27.120 --> 00:29:34.480
X-Account, wird ganz viel Propaganda geretweetet und sie kommen nicht mehr dran und da steht ihr

00:29:34.480 --> 00:29:42.480
Name drauf. Das ist so Account Takeover, Fall von IdentitÃ¤tstiefstahl. Normalerweise merken sie das,

00:29:42.480 --> 00:29:49.800
oder wenn zum Beispiel in ihrem Ebay-Account irgendwas ersteigert wird in ihrem Namen und

00:29:49.800 --> 00:29:55.400
sie sollen dann bezahlen, dann beschweren sich Leute bei ihnen. Das in AnfÃ¼hrungsrichtung geht

00:29:55.400 --> 00:30:00.840
noch, weil sie das mitkriegen, aber es gibt ja auch diesen New-Account-IdentitÃ¤tstiefstahl. Das

00:30:00.840 --> 00:30:08.680
heiÃŸt, irgendwer legt in ihrem Namen mit ihren Daten irgendwo einen Account an und bestellt dann

00:30:08.680 --> 00:30:16.280
fleiÃŸig und sie kriegen dann die Rechnung. Hoffentlich merken sie das dann und das ist

00:30:16.280 --> 00:30:22.440
sehr viel schwieriger, dann herauszukriegen, ob so was funktioniert, ob so was passiert.

00:30:22.440 --> 00:30:32.240
Genau, fÃ¼r den HÃ¤ndler bei diesem New-Account-Fraud, fÃ¼r den HÃ¤ndler ist es nÃ¤mlich zunÃ¤chst mal

00:30:32.240 --> 00:30:37.480
vÃ¶llig unklar, wenn er bei ihnen zum Beispiel anruft oder sie kontaktiert, sie haben da was

00:30:37.480 --> 00:30:43.400
bestellt und noch nicht bezahlt, bezahlen sie mal endlich. FÃ¼r den HÃ¤ndler kann nicht unterscheiden,

00:30:43.400 --> 00:30:49.840
ist sehr schwer zu unterscheiden, ist das jetzt IdentitÃ¤tstiefstahl oder sagen sie einfach,

00:30:49.840 --> 00:30:55.800
ne, das war ich nicht. Also es ist unglaublich schwer, unglaublich fiese Situationen, in die

00:30:55.800 --> 00:31:02.120
man da reinkommen kann. Das wird natÃ¼rlich umso stÃ¤rker vereinfacht, je eher Leute mehr Ã¼ber sie

00:31:02.120 --> 00:31:09.680
rauskriegen. Das heiÃŸt, wenn, das ist ja auch Account Takeover, englische Journalisten haben ja dann

00:31:09.680 --> 00:31:15.000
teilweise auch Accounts von Prominenten Ã¼bernommen, dadurch, dass sie die Sicherheitsfragen beantworten

00:31:15.000 --> 00:31:21.720
konnten, die beim Passwortreset zum Beispiel benÃ¶tigt werden. Also auch eine Frage von

00:31:21.720 --> 00:31:30.320
personenbezogene Daten. Am Ende weitere Gefahren fÃ¼r die PrivatsphÃ¤re, wenn halt die

00:31:30.320 --> 00:31:38.720
personenbezogenen Daten nicht geschÃ¼tzt sind. Immer das Problem, ja wenn klar ist, dass Ã¼berall,

00:31:38.720 --> 00:31:45.880
wo sie sich online bewegen, Daten Ã¼ber sie gesammelt werden, dann fÃ¼hrt das automatisch dazu,

00:31:45.880 --> 00:31:51.880
dass sie sich fragen, ist das jetzt gut, was ich jetzt mache oder kann das irgendwie negativ,

00:31:51.880 --> 00:31:58.320
kann das irgendwie negativ aussehen nach auÃŸen. Es gibt diesen Begriff der Click Fear, ich weiÃŸ

00:31:58.320 --> 00:32:03.040
nicht, ob sie das schon mal hatten, dass sie mit der Maus Ã¼ber einen Link gegangen sind und gesagt

00:32:03.040 --> 00:32:06.960
haben, wenn ich jetzt darauf klicke, was fÃ¼r negative Auswirkungen hat es denn fÃ¼r mich,

00:32:06.960 --> 00:32:12.480
wenn andere Leute wissen, dass ich da drauf geklickt habe. Und mittlerweile weiÃŸ man ja,

00:32:12.480 --> 00:32:18.800
dass im Prinzip jeder Klick auch registriert wird. Das heiÃŸt also, der mangelnde Schutz

00:32:18.800 --> 00:32:25.120
personenbezogener Daten fÃ¼hrt dazu, dass man sich implizit zurÃ¼ckhÃ¤lt, also die freie Entfaltung

00:32:25.120 --> 00:32:29.560
der PersÃ¶nlichkeit etwas einschrÃ¤nkt. Und schlussendlich Manipulation der PersÃ¶nlichkeit,

00:32:29.560 --> 00:32:36.720
wie gesagt einer von vielen Bedrohungen der PrivatsphÃ¤re, wenn man sich vÃ¶llig,

00:32:36.720 --> 00:32:43.120
also wenn man sich einem der Internetkonzerne anvertraut, also Google und da entsprechend die

00:32:43.120 --> 00:32:48.040
Datenschutzeinstellungen nicht macht, da gibt es diese Google Timeline, also man kann im Prinzip

00:32:48.040 --> 00:32:55.040
dann nachgucken, was man vor zehn Jahren an Google Suche eingegeben hat. Und im Prinzip kann man an den

00:32:55.040 --> 00:32:58.720
Google Suchen, die man eingegeben hat, nachvollziehen, was man zu dem Zeitpunkt

00:32:58.720 --> 00:33:06.760
gedacht hat. Was einen bewegt hat. Und das kann Google im Prinzip so lange wie sie, also Google

00:33:06.760 --> 00:33:14.480
steht nur fÃ¼r Apple, Facebook, fÃ¼r alle diese Konzerne, die die Daten sammeln als GeschÃ¤ftszweck

00:33:14.480 --> 00:33:19.800
haben. Also Google weiÃŸ dann, was sie vor zehn Jahren gedacht haben. Sie wissen es vielleicht

00:33:19.800 --> 00:33:24.320
nicht mehr, aber Google weiÃŸ es noch oder kann es im Prinzip rauskriegen. Und das ist natÃ¼rlich

00:33:24.560 --> 00:33:31.640
was, was ein Datenschutz ist, den man sehr gut nutzen kann, um sie zu beeinflussen. Ihre

00:33:31.640 --> 00:33:36.560
geheimsten WÃ¼nsche weiÃŸ Google und kann natÃ¼rlich auch sie entsprechend manipulieren,

00:33:36.560 --> 00:33:43.480
wie Nachrichtendienste das gerne machen. Bis hin zur Erpressung, also wenn sich, jetzt muss ich

00:33:43.480 --> 00:33:58.600
aber tatsÃ¤chlich mal anhalten, Entschuldigung. Gut. Genau. Wie kann man denn da dem abhelfen?

00:33:58.600 --> 00:34:04.400
NatÃ¼rlich Datenschutz. Was bedeutet Datenschutz? Im Grunde genommen ist es ja so, dass man als

00:34:04.400 --> 00:34:10.080
Data Subject, also jemand, der Daten, der personenbezogene Daten besitzt. Also die

00:34:10.080 --> 00:34:17.280
personenbezogene Daten, die werden weitergegeben an Leute, die dann diese Daten halten, die auch

00:34:17.280 --> 00:34:23.120
rechtmÃ¤ÃŸig vielleicht oder auch brauchen. Und die kÃ¶nnen natÃ¼rlich diese Daten weitergeben. Und das

00:34:23.120 --> 00:34:31.720
kann dazu fÃ¼hren, dass man halt Intrusions of Privacy hat. Der klassische Ansatz fÃ¼r Datenschutz

00:34:31.720 --> 00:34:39.120
ist, diese Information Collection zu unterbinden. Also das heiÃŸt, also Informationsflusskontrolle

00:34:39.160 --> 00:34:48.760
zu machen und dafÃ¼r zu sorgen, dass man seine Daten sozusagen bei sich behÃ¤lt. Das ist heute

00:34:48.760 --> 00:34:56.040
natÃ¼rlich schwerer als frÃ¼her. Ãœberall im Prinzip muss man seine Daten preisgeben, egal ob man will

00:34:56.040 --> 00:35:03.360
oder nicht. Und das ist also heutzutage sehr, sehr schwer umzusetzen. Und im Prinzip, der heutige

00:35:03.360 --> 00:35:08.560
Ansatz ist im Prinzip eine Kombination aus datenschutzfÃ¶rdernde Techniken, die wir auch

00:35:08.560 --> 00:35:13.760
noch kennenlernen werden. Also dass man zum Beispiel bestimmte Datenschutzeinstellungen macht,

00:35:13.760 --> 00:35:18.280
dass etwas gar nicht erst erhoben wird oder dass man Techniken benutzt wie VPN, dass bestimmte

00:35:18.280 --> 00:35:25.960
Sachen gar nicht erhebbar sind. Plus rechtliche Bestimmungen, wie zum Beispiel die Datenschutz

00:35:25.960 --> 00:35:30.240
Grundverordnung, auf die ich auch noch gleich eingehen werde, wo man dann spÃ¤ter, wenn ein

00:35:30.240 --> 00:35:35.160
VerstoÃŸ gegen Datenschutzregeln offenbar wird, dagegen klagen kann und Leute dazu zwingen kann,

00:35:35.280 --> 00:35:42.240
den Datenschutz wieder einzuhalten. Aber das Problem heutzutage ist, im Prinzip muss man bei

00:35:42.240 --> 00:35:47.840
der Datensammlung mitmachen heutzutage, um an einem gesellschaftlichen Leben teilzunehmen. Also wer

00:35:47.840 --> 00:35:53.760
heutzutage nicht im Internet bestimmte Sachen macht, der ist abgehÃ¤ngt, weiÃŸ ich gar nicht,

00:35:53.760 --> 00:35:58.920
oder fÃ¼hlt sich jedenfalls abgehÃ¤ngt. Insofern ist das heutzutage schwieriger als man denkt.

00:35:58.920 --> 00:36:04.680
Deswegen machen wir einen ganz kurzen Schnelldurchlauf durch die Prinzipien

00:36:04.760 --> 00:36:11.080
des Datenschutzrechts. Datenschutzrecht ist ja auch was Rechtliches. Es gibt das Bundesdatenschutzgesetz,

00:36:11.080 --> 00:36:20.560
aber auch die DSGVO. Das Datenschutzrecht, das regelt im Prinzip oder das gewÃ¤hrleistet,

00:36:20.560 --> 00:36:24.280
das soll das Recht auf informationelle Selbstbestimmung gewÃ¤hrleisten. Im Prinzip

00:36:24.280 --> 00:36:28.200
beschreibt es einen Interessenausgleich. NatÃ¼rlich die Datenschutzinteressen des

00:36:28.200 --> 00:36:35.680
Einzelnen, also von Ihnen. Aber es gibt natÃ¼rlich berechtigte Interessen staatlicher oder privater

00:36:35.680 --> 00:36:39.640
Datenverarbeiter, zum Beispiel das Einwohner-Meldeamt, hatten berechtigtes Interesse,

00:36:39.640 --> 00:36:44.160
ihren Namen und ihre Adresse zu wissen. Aber es gibt auch berechtigte Interessen der Allgemeinheit.

00:36:44.160 --> 00:36:50.240
Also das heiÃŸt, wenn die Polizei zum Beispiel sie sucht, dann muss sie auch irgendwie das Recht

00:36:50.240 --> 00:36:54.960
haben, ihre Daten zu verarbeiten, also um vor KriminalitÃ¤t zum Beispiel zu schÃ¼tzen.

00:36:54.960 --> 00:37:02.600
Das Datenschutzrecht heutzutage ist eigentlich bestimmt, es gibt das Bundesdatenschutzgesetz,

00:37:02.600 --> 00:37:06.440
aber eigentlich durch die Datenschutzgrundverordnung. Die europÃ¤ische,

00:37:06.440 --> 00:37:13.240
es ist eine europÃ¤ische Regulierung, die das Datenschutzrecht in Europa vereinheitlichen

00:37:13.240 --> 00:37:19.440
sollte oder vereinleichtigt hat. Das kann man denke ich schon, das gilt seit Mai 2018,

00:37:19.440 --> 00:37:24.960
ist im Prinzip ein Meilenstein, wÃ¼rde ich schon sagen, im Bereich der informationellen

00:37:24.960 --> 00:37:30.000
Selbstbestimmung. Es gab natÃ¼rlich da AusreiÃŸer nach oben und wie nach unten,

00:37:30.000 --> 00:37:35.600
also hier zum Beispiel AusreiÃŸer nach unten. Also ein mangelndes VerstÃ¤ndnis von DSGVO sagt dann,

00:37:35.600 --> 00:37:42.360
okay, man darf noch nicht mal als Hausvermieter die Namen der Mieter am Klingelschild haben.

00:37:42.360 --> 00:37:46.800
Das ist natÃ¼rlich Unsinn, das ist natÃ¼rlich notwendig, dass da der Name der Mieter drauf ist,

00:37:47.480 --> 00:37:53.280
aber solche Meldungen bringen dann die DSGVO immerhin wieder in Verruf, obwohl das vÃ¶llig

00:37:53.280 --> 00:38:03.320
unsinn ist. Das, wo die DSGVO dann wieder positiv auffÃ¤llt, ist, dass wenn tatsÃ¤chlich Datenverarbeiter

00:38:03.320 --> 00:38:07.760
wie Google oder die groÃŸen Internetkonzerne oder andere gegen das Datenschutzrecht verstoÃŸen und

00:38:07.760 --> 00:38:14.400
nicht ihre Einwilligung haben, wenn sie zum Beispiel ihre Daten verarbeiten, dann kÃ¶nnen

00:38:14.400 --> 00:38:22.080
tatsÃ¤chlich jetzt auch empfehlliche Strafen verhÃ¤ngt werden. Die Grundprinzipien, die sie

00:38:22.080 --> 00:38:28.400
haben, die Rechte, die sie haben, wenn sie oder die Prinzipien, an die sich Datenverarbeiter

00:38:28.400 --> 00:38:37.680
halten mÃ¼ssen in der DSGVO, sind im Prinzip drei Sachen. Das erste ist Verbot mit Erlaubnisvorbehalt,

00:38:37.680 --> 00:38:42.360
was bedeutet das? Die Verarbeitung ihrer personenbezogenen Daten ist erstmal verboten,

00:38:42.520 --> 00:38:49.800
es sei denn, der Betroffene hat eingewilligt, dass die Daten verarbeitet werden oder es gibt

00:38:49.800 --> 00:38:55.240
eine gesetzliche Erlaubnis diese Daten zu verarbeiten. Die Einwilligung, das haben Sie

00:38:55.240 --> 00:39:00.760
schon hÃ¤ufig mitgekriegt, das sind die Cookie-Banner zum Beispiel. Also da merkt man, dass die

00:39:00.760 --> 00:39:06.200
Einwilligung auch manchmal nur pro forma erhoben wird. Sie klicken ja meistens wahrscheinlich weg

00:39:06.200 --> 00:39:13.000
oder mÃ¶glichst schnell weg damit. Die Frage ist, ob es bestimmte Anforderungen an die Einwilligung

00:39:13.000 --> 00:39:17.280
geben muss, wie zum Beispiel bei Banken, die sich dreimal versichern lassen, dass sie die

00:39:17.280 --> 00:39:23.120
Informationen Ã¼ber die Risiken von Krediten zum Beispiel wahrgenommen haben, dass sie sich spÃ¤ter

00:39:23.120 --> 00:39:30.960
nicht beschweren, dass sie nichts davon wussten. Das zweite Prinzip ist die Zweckbindung und

00:39:31.440 --> 00:39:37.320
heiÃŸt, die Verarbeitung der Daten muss an einen bestimmten Zweck gebunden sein, ist an einen

00:39:37.320 --> 00:39:40.440
bestimmten Zweck gebunden. Das heiÃŸt, wenn die Daten erhoben werden, dann muss gesagt werden,

00:39:40.440 --> 00:39:46.880
wofÃ¼r werden die denn erhoben? Und wenn dieser Zweck wegfÃ¤llt, also und die dÃ¼rfen auch nur

00:39:46.880 --> 00:39:50.600
fÃ¼r diesen Zweck verarbeitet werden, wenn der Zweck wegfÃ¤llt, mÃ¼ssen die Daten auch gelÃ¶scht

00:39:50.600 --> 00:39:54.080
werden und sie dÃ¼rfen auch nicht fÃ¼r einen anderen Zweck verarbeitet werden. Das ist die

00:39:54.080 --> 00:40:00.400
Zweckbindung. Und das dritte ist die Datenminimierung, das dritte Grundprinzip,

00:40:00.400 --> 00:40:05.640
Datenminimierung. Die Verarbeitung von Daten muss auf das notwendige MaÃŸ beschrÃ¤nkt sein. Also es

00:40:05.640 --> 00:40:10.760
dÃ¼rfen auch tatsÃ¤chlich nur Daten erhoben werden, die fÃ¼r den Zweck, der beschrieben ist, tatsÃ¤chlich

00:40:10.760 --> 00:40:14.840
auch notwendig sind. Das heiÃŸt, wenn Sie es nÃ¤chstes Mal im Hotel sind und die alle mÃ¶glichen

00:40:14.840 --> 00:40:18.240
Daten von Ihnen haben wollen, dann kÃ¶nnen Sie auch einfach Sachen mal leer lassen und sagen,

00:40:18.240 --> 00:40:25.560
wofÃ¼r brauchen Sie das Ã¼berhaupt? Genau und Sie haben natÃ¼rlich auch Rechte, betroffene Rechte,

00:40:25.560 --> 00:40:30.120
Recht auf Auskunft. Sie kÃ¶nnen bei Leuten, die Daten oder bei Organisationen die Daten von Ihnen

00:40:30.120 --> 00:40:36.560
verarbeiten, einfach Fragen der Datenschutzauskunft machen nach Paragraph XY DSGVO. KÃ¶nnen Sie

00:40:36.560 --> 00:40:39.920
hinschreiben, sagen, was fÃ¼r Daten haben Sie denn mÃ¶glich gespeichert? Und dann warten Sie mal ab,

00:40:39.920 --> 00:40:46.200
was fÃ¼r eine Reaktion dann kommt. HÃ¤? Oder meistens kommt dann irgendwie so eine Antwort von der

00:40:46.200 --> 00:40:51.240
Rechtsabteilung, sagt, wir machen nichts Schlimmes mit Ihren Daten, aber die Daten, die Sie gespeichert

00:40:51.240 --> 00:40:56.400
sind, werden Ihnen trotzdem nicht ausgehÃ¤ndigt. Sie haben das Recht auf Berichtigung oder LÃ¶schen

00:40:56.400 --> 00:41:01.920
von Daten. Also wenn Sie dann die Datenschutzauskunft kriegen und sagen, das stimmt was nicht, dann

00:41:01.920 --> 00:41:06.240
haben Sie das Recht darauf, dass das korrigiert wird und dass auch Daten gelÃ¶scht werden. Und

00:41:06.240 --> 00:41:10.800
Sie haben sogar das Recht auf DatenÃ¼bertragbarkeit, also DatenportabilitÃ¤t. Das soll im Prinzip das

00:41:10.800 --> 00:41:19.680
Login auf bestimmte Dienstleister erschweren. Das heiÃŸt, Sie kÃ¶nnen zum Beispiel zu Facebook

00:41:19.680 --> 00:41:23.000
gehen und sagen, so alle meine Daten, die in meinem Facebook-Account gespeichert sind,

00:41:23.000 --> 00:41:28.760
gib mir die mal, lÃ¶sch die und dann gehen Sie zu Google Plus, gibt es das noch, oder zu irgendeinem

00:41:28.760 --> 00:41:35.440
anderen Social Media Anbieter und sagen, so hier habe ich meine Facebook-Daten, importiere die doch

00:41:35.440 --> 00:41:40.080
mal, sodass ich da genauso weitermachen kann, wie ich bei Facebook aufgehÃ¶rt habe. Das Recht haben

00:41:40.080 --> 00:41:46.080
Sie. Das geht auch teilweise, also das Begriff DatenportabilitÃ¤t. Ich weiÃŸ nicht, hat das jemand

00:41:46.080 --> 00:41:52.000
schon mal versucht bei Ihnen? Ich kann Sie nur ermutigen, das zu versuchen. Ja, das hat schon

00:41:52.000 --> 00:42:05.080
jemand versucht. Bitte sagen Sie mal. Mit Passwortmanagern. Okay, okay. Okay, ja, das macht

00:42:05.080 --> 00:42:12.000
Sinn, aber wer das mal bei Facebook oder Google versucht und da Erfahrungen gesammelt hat, der

00:42:12.000 --> 00:42:17.880
kann sich gerne mal bei mir melden. Das alles macht so den Eindruck, als wenn Datenschutz ihre

00:42:17.880 --> 00:42:22.640
Privatsache ist. Und es ist ja im Prinzip auch ihre Privatsache. Sie mÃ¼ssen darauf achten, was mit

00:42:22.640 --> 00:42:28.160
Ihren Daten passiert. Das ist zwar anstrengend, aber es ist wie so ein bisschen so Ã¶komÃ¤ÃŸig.

00:42:28.240 --> 00:42:36.000
Das Problem ist, dass man heutzutage weiÃŸ, dass es nicht immer nur eine Privatsache ist, weil das,

00:42:36.000 --> 00:42:41.160
was andere Leute machen, auch auf sie Einwirkungen hat. Und das ist dieser Begriff prÃ¤diktive

00:42:41.160 --> 00:42:48.040
Privatheit, den der Philosoph Rainer MÃ¼lhoff mal geprÃ¤gt hat. Das Problem ist nÃ¤mlich, dass Alice

00:42:48.040 --> 00:42:54.120
zum Beispiel jetzt alles richtig macht und ihre Daten geheim hÃ¤lt, aber bestimmte Daten Ã¼ber Alice

00:42:54.120 --> 00:42:58.980
natÃ¼rlich bekannt sind. Also zum Beispiel, wo sie wohnt oder sowas, aber vielleicht nicht andere

00:42:58.980 --> 00:43:04.600
Sachen. Ihre sexuellen PrÃ¤ferenzen oder ihr Geschlecht oder ihr gefÃ¼hltes Geschlecht zum

00:43:04.600 --> 00:43:11.560
Beispiel. Das Problem ist, wenn es Hilfsdaten oder sonstige Daten Ã¼ber Alice gibt, dann kann man

00:43:11.560 --> 00:43:19.200
natÃ¼rlich mit KI-Modellen heutzutage aus diesen Hilfsdaten die andere Daten ableiten. Und warum

00:43:19.280 --> 00:43:24.000
kann man das? Weil diese prÃ¤diktiven Modelle, diese KI-Modelle auf den Daten von ganz vielen

00:43:24.000 --> 00:43:29.800
anderen Leuten trainiert worden sind. Also die Hilfsdaten sind zum Beispiel Facebook-Likes von

00:43:29.800 --> 00:43:37.520
Alice. Die sagen ziemlich viel Ã¼ber einen persÃ¶nlich aus. Und man kann auf den Facebook-Likes zum

00:43:37.520 --> 00:43:43.680
Beispiel die sexuelle IdentitÃ¤t oder sexuelle PrÃ¤ferenzen lernen, dadurch, dass man diese

00:43:43.680 --> 00:43:48.360
Daten von anderen Leuten hat. Man kann mit relativ hoher Wahrscheinlichkeit oder hoher

00:43:48.360 --> 00:43:56.560
Signifikanz dann tatsÃ¤chlich von Alice diese Daten auch auch vorhersagen. Das heiÃŸt, da kann

00:43:56.560 --> 00:44:02.120
Alice so viel machen, wie sie mÃ¶chte. Okay, sollte vielleicht nicht so viele Facebook-Likes setzen,

00:44:02.120 --> 00:44:08.200
aber im Prinzip, Alice kann ihre sexuelle IdentitÃ¤t zum Beispiel geheim halten, aber

00:44:08.200 --> 00:44:13.200
trotzdem wird sie offenbar. Und das liegt daran, dass alle anderen sozusagen nicht auf ihre Daten

00:44:13.520 --> 00:44:19.280
achten. Und das kann natÃ¼rlich auch Auswirkungen auf, also die Privatheit ist also nicht nur ein

00:44:19.280 --> 00:44:28.200
Problem von Einzelnen, tatsÃ¤chlich von allen. Gut, ich mache noch die AnonymitÃ¤tsmaÃŸe und dann

00:44:28.200 --> 00:44:34.960
machen wir eine ganz kurze Pause. Die Frage ist, wenn man jetzt DatenbestÃ¤nde hat, also zum

00:44:34.960 --> 00:44:40.360
Beispiel als Wissenschaftler DatenbestÃ¤nde hat, und ich mÃ¶chte gerne die Daten anderen Leuten

00:44:40.360 --> 00:44:47.040
geben, aber ich mÃ¶chte gerne die PrivatsphÃ¤re von Leuten schÃ¼tzen. Zum Beispiel bei Gesundheitsdaten

00:44:47.040 --> 00:44:51.720
wird das ja hÃ¤ufig diskutiert. Also unter welchen Bedingungen kann man die zum Beispiel weitergeben?

00:44:51.720 --> 00:44:56.480
Die LÃ¶sung ist natÃ¼rlich, man analysiert die Daten, die da drin sind, aber die Frage ist,

00:44:56.480 --> 00:45:01.640
wie macht man das und wie bewertet man vor allem, wie gut die analysiert sind? Und da gibt es

00:45:01.640 --> 00:45:07.280
verschiedene MaÃŸe, die man da machen kann und wir schauen uns jetzt mal zwei von diesen MaÃŸen an.

00:45:07.280 --> 00:45:15.440
Das, was man vermeiden will, sind sogenannte VerknÃ¼pfungsangriffe. VerknÃ¼pfungsangriffe

00:45:15.440 --> 00:45:21.440
sehen so aus, dass zum Beispiel das hier sind die Daten, die irgendwie ein medizinischer Forscher

00:45:21.440 --> 00:45:28.760
verÃ¶ffentlicht hat. Also zum Beispiel Basisdaten, wo er bestimmte medizinische Sachverhalte,

00:45:28.760 --> 00:45:36.880
Diagnosen vorhergesagt hat aus bestimmten anderen Daten. Und die Daten, die sind jetzt insofern

00:45:36.880 --> 00:45:42.320
anonymisiert, dass da kein Name drinne steht, keine Adresse drinne steht. Die Adresse ist hier durch

00:45:42.320 --> 00:45:50.520
SIP, die Postleitzahl zum Beispiel, erproximiert. Aber das sind Daten, die einfach so fÃ¼r sich

00:45:50.520 --> 00:46:01.680
verÃ¶ffentlicht worden sind. So hier wollte ich was malen. Also das hier sind die, das sind hier die

00:46:01.680 --> 00:46:12.120
verÃ¶ffentlichten, pseudonymisierten oder verÃ¶ffentlichte Daten aus der medizinischen

00:46:12.120 --> 00:46:18.520
Forschung. Jetzt gibt es aber andere Daten, die auch verÃ¶ffentlicht werden kÃ¶nnten. Zum Beispiel

00:46:18.520 --> 00:46:25.120
hier in den Vereinigten Staaten die die Liste der WÃ¤hler, die in der Ã¶ffentlichen Liste eingetragen

00:46:25.120 --> 00:46:38.480
sind. Also das sind auch verÃ¶ffentlichte Daten aus anderen Quellen. Und wenn die sich jetzt

00:46:38.480 --> 00:46:43.880
Ã¼berschneiden in bestimmten Aspekten, das ist hier diese Ãœberschneidung hier, dann kann man

00:46:43.880 --> 00:46:52.480
die miteinander verknÃ¼pfen. Und die Attribute, die man da benutzt um die zu verknÃ¼pfen,

00:46:52.480 --> 00:46:59.200
die nennt man, also die Menge an Attributen, die nennt man, das sind die sogenannten quasi

00:46:59.200 --> 00:47:09.960
Identifier. Das ist im Prinzip eine Sammlung von Attributen, die eine Person potenziell

00:47:09.960 --> 00:47:16.840
eindeutig identifizieren kÃ¶nnen. Und wenn man jetzt nÃ¤mlich diese beiden DatenbestÃ¤nde verknÃ¼pft

00:47:16.840 --> 00:47:22.400
und nicht auf eine bestimmte Eigenschaft der DatenbestÃ¤nde achtet, dann kann man nÃ¤mlich

00:47:22.400 --> 00:47:28.680
plÃ¶tzlich aus der VerknÃ¼pfung dieser beiden DatenbestÃ¤nde jetzt zum Beispiel den Namen,

00:47:28.680 --> 00:47:33.400
also den Namen von jemandem ergÃ¤nzen, der hier zum Beispiel eine bestimmte Diagnose hatte.

00:47:33.400 --> 00:47:41.120
Dann gibt es tatsÃ¤chlich Beispiele aus der Praxis in den Vereinigten Staaten, wo ein

00:47:41.680 --> 00:47:47.280
Gouverneur von Massachusetts aus dieser VerknÃ¼pfung plÃ¶tzlich nachgewiesen werden konnte,

00:47:47.280 --> 00:47:52.760
dass er eine bestimmte medizinische Diagnose hatte, was nicht Ã¶ffentlich bekannt war.

00:47:52.760 --> 00:48:00.560
Und um so was zu verhindern, braucht man natÃ¼rlich DatenbestÃ¤nde, die eine bestimmte

00:48:00.560 --> 00:48:12.760
AnonymitÃ¤tqualitÃ¤t haben. Und eine von dieser Art, das zu messen, ist der Begriff der K-AnonymitÃ¤t.

00:48:12.760 --> 00:48:21.600
Und die Definition von K-AnonymitÃ¤t sagt, eine Tabelle oder ein Datenbestand ist K-anonym bezÃ¼glich

00:48:21.600 --> 00:48:27.440
eines quasi Identifiers QI, also eine Menge von Attributen. Wenn jede Zeile mindestens

00:48:27.520 --> 00:48:33.400
K mal in der Tabelle vorkommt, wenn man nur die Attribute im quasi Identifier sich anschaut.

00:48:33.400 --> 00:48:43.000
Also mal angenommen, das hier ist eine Tabelle, die verÃ¶ffentlicht wird und die quasi Identifier sind

00:48:43.000 --> 00:48:51.760
jetzt diese, das ist Race, Birth, Gender und Zipcode, also die ersten vier Spalten. Das sind

00:48:51.760 --> 00:49:00.440
unsere quasi Identifier. Und K-anonymitÃ¤t besagt, wenn man diese Tabelle anschaut und

00:49:00.440 --> 00:49:07.840
nur die quasi Identifier betrachtet, dann muss jede Zeile mindestens K mal vorkommen. Wir kÃ¶nnen

00:49:07.840 --> 00:49:13.080
mal schauen, wenn man die rechte Spalte weglÃ¤sst, da sieht man, hier kommt es zweimal vor, das ist

00:49:13.080 --> 00:49:23.880
zweimal, zweimal, zweimal, hier sogar dreimal und hier auch mal zweimal. Das heiÃŸt, die ist fÃ¼r K

00:49:23.880 --> 00:49:33.320
gleich zwei K-Anonymen. Warum ist das gut? Das bedeutet, dass wenn man jetzt Ã¼ber diese quasi

00:49:33.320 --> 00:49:39.960
Identifier einen VerknÃ¼pfungsangriff macht, dann ist die kleinste Datenmenge, auf die man dann eine

00:49:39.960 --> 00:49:45.200
VerknÃ¼pfung machen kann, K-Elemente groÃŸ. Also wenn K gleich zwei ist, dann kann man nicht

00:49:45.200 --> 00:49:51.000
eindeutig jemand identifizieren, sondern man landet immer bei zwei Leuten, die man identifizieren kann.

00:49:51.000 --> 00:49:57.720
Und das ist besser, als wenn sie eindeutig identifizierbar sind. Und je grÃ¶ÃŸer K ist,

00:49:57.720 --> 00:50:05.240
desto grÃ¶ÃŸer ist natÃ¼rlich auch der Grad anonymitÃ¤t, die man da erreichen kann. Machen wir

00:50:05.320 --> 00:50:09.760
mal ein Beispiel, oder ich frage mal, wer ist jetzt noch dabei? K-AnonymitÃ¤t, okay. Machen wir mal ein

00:50:09.760 --> 00:50:16.640
Beispiel, auch wo man die Probleme sieht, auch aus dem Originalpapier. Mal angenommen, das hier links

00:50:16.640 --> 00:50:23.840
oben, PT, das ist die Originalquelle, das ist die Private Table, die man dann publiziert, aber die

00:50:23.840 --> 00:50:30.160
publiziert man natÃ¼rlich nicht in der Art, wie sie da steht, sondern K-Anonymen. Also man kann sie

00:50:30.160 --> 00:50:38.760
zum Beispiel hier publizieren, dadurch, dass man sagt, okay, ich mache meinen Raster grÃ¶ber,

00:50:38.760 --> 00:50:44.120
zum Beispiel. Das Birthdate wird jetzt nicht auf Geburtsdatum runtergebrochen, sondern auf das Jahr.

00:50:44.120 --> 00:50:52.000
Dadurch wird man grÃ¶ber und man schlieÃŸt dann einzelne Zeilen dann zusammen. Und der Quasi-

00:50:52.000 --> 00:50:58.800
Identifier, das sind jetzt nochmal die ersten, das ist hier unser Quasi- Identifier Set. Man sieht,

00:50:58.880 --> 00:51:04.280
dass man auch hier zum Beispiel bei RACE kann man auch K-AnonymitÃ¤t dadurch erreichen, dass man

00:51:04.280 --> 00:51:12.120
verallgemeinert oder dass man EintrÃ¤ge weglÃ¤sst zum Beispiel, oder Black oder White einfach auf

00:51:12.120 --> 00:51:17.280
Person geht zum Beispiel, und man nicht mehr weiÃŸ, ob das Black oder White ist. Das heiÃŸt, hier

00:51:17.280 --> 00:51:25.000
sieht man, hier hat man K gleich zwei AnonymitÃ¤t, das ist gleich, das ist gleich, das ist gleich.

00:51:25.000 --> 00:51:32.200
Man kann auch hier verallgemeinern die Postleitzahl, das heiÃŸt, hier hat man fÃ¼r K gleich zwei

00:51:32.200 --> 00:51:37.560
K-AnonymitÃ¤t. Das Problem ist, wenn man den gleichen Datenbestand auf andere Art zum

00:51:37.560 --> 00:51:45.560
Beispiel verÃ¶ffentlicht und auf andere Art zum Beispiel K-AnonymitÃ¤t herstellt, zum Beispiel,

00:51:45.560 --> 00:51:52.280
dass man die Jahreszahl verallgemeinert oder hier zum Beispiel das Geschlecht verallgemeinert,

00:51:52.280 --> 00:51:57.800
dann kann man natÃ¼rlich aus diesen beiden DatenbestÃ¤nden, wenn das hier wieder der

00:51:57.800 --> 00:52:02.920
Quasi- Identifier ist, kann man durch VerknÃ¼pfungen dann wieder einen Datenbestand erzeugen,

00:52:02.920 --> 00:52:14.960
der wieder eindeutiger ist und wo man dann aus dem RÃ¼ckrechnen schon hier die eine Person dann

00:52:14.960 --> 00:52:23.960
entsprechend wieder eindeutig identifizieren kann. Das heiÃŸt, das Problem ist, wenn GT1 und GT2,

00:52:23.960 --> 00:52:30.440
diese beiden DatenbestÃ¤nde verÃ¶ffentlicht werden, kann man wieder Ã¼ber die Werte die Tabelle LT

00:52:30.440 --> 00:52:38.360
erstellen und dann, die ist dann nicht mehr K-Gleich-Zwei-Anonymen. Das heiÃŸt, das Problem

00:52:38.360 --> 00:52:42.640
wÃ¤re nicht entstanden, wenn man natÃ¼rlich aufpassen wÃ¼rde, was man aus PT alles ableitet.

00:52:42.640 --> 00:52:51.320
Genau, wenn die nicht unabhÃ¤ngig voneinander abgeleitet worden wÃ¤ren. Das heiÃŸt, K-AnonymitÃ¤t

00:52:51.320 --> 00:53:01.520
ist leicht herzustellen, aber auch leicht aufzulÃ¶sen. Gut, machen wir noch kurz den zweiten

00:53:01.520 --> 00:53:09.680
Ansatz PrivatsphÃ¤re herzustellen. Das ist der Begriff der Differential Privacy. Die Idee dabei

00:53:09.680 --> 00:53:15.800
ist, dass das ein statistisches MaÃŸ fÃ¼r Privatheit ist. Wenn das hinzufÃ¼gen oder

00:53:15.800 --> 00:53:20.600
entfernen einer Person keinen groÃŸen Unterschied bezÃ¼glich der Analyse macht, dann bleibt die

00:53:20.600 --> 00:53:28.640
Privatheit gewahrt. Also wenn man hier eine Datenbank hat, zum Beispiel, und eine Datenbank D1 und D2,

00:53:28.640 --> 00:53:33.440
und der einzige Unterschied zwischen diesen beiden Datenbanken ist, dass in D1 der Datensatz einer

00:53:33.440 --> 00:53:39.920
Person P drin ist und in D2 nicht. Jetzt macht man die gleiche Analyse auf diesen beiden Daten

00:53:39.920 --> 00:53:45.160
setzen und hat zwei verschiedene Antworten. Und wenn die Antworten, die Analysen, die man darauf

00:53:45.160 --> 00:53:50.920
machen kann, hinreichend klein oder hinreichend wenig unterscheidbar ist durch so einen Epsilon,

00:53:50.920 --> 00:54:00.440
irgendwie statistisch, durch einen ganz kleinen Wert Epsilon, dann sagt man, wenn das fÃ¼r beliebige

00:54:00.440 --> 00:54:06.240
Analysen und beliebige Antworten der Fall ist, dann sagt man, das ist Differential Private, diese

00:54:06.240 --> 00:54:14.360
Datenbank. Genau, das ist ein statistischer Privatheitsbegriff, der auch eine formal

00:54:14.360 --> 00:54:20.920
nachweisbare Privatsch garantie gibt. Wie erreicht man das? Man muss halt irgendwie in diese Datenbanken

00:54:20.920 --> 00:54:29.880
rauschen oder man muss unschÃ¤rf hinschÃ¼gen, damit die Tatsache ob eine Person P drin ist oder

00:54:29.880 --> 00:54:36.120
nicht keinen Unterschied macht, aber im konkreten Fall immer schwierig herzustellen. Da muss man

00:54:36.120 --> 00:54:40.560
zum Beispiel Ã¼ber statistische Verteilung von Attributen gut Bescheid wissen, weil die Verteilungen

00:54:40.560 --> 00:54:45.560
dÃ¼rfen sich nicht Ã¤ndern. Das ist schwer angreifbar, aber auch schwer anwendbar, Differential Privacy.

00:54:45.560 --> 00:54:54.240
Das, um es zu kontrastieren von k-AnonymitÃ¤t. Gut, das war, machen wir eine ganz kurze Pause und

00:54:54.240 --> 00:55:04.920
dann geht es weiter mit Anonymy Kommunikation. So, machen wir noch eine halbe Stunde Anonymy

00:55:04.920 --> 00:55:08.960
Kommunikation. Das ist wahrscheinlich sogar prÃ¼fungsrelevanter als die ganze Stunde,

00:55:08.960 --> 00:55:15.840
die ich vorher geredet habe. Gut, jetzt wird es auch ein bisschen technischer noch. Das andere

00:55:15.840 --> 00:55:21.600
ist eher so Allgemeinbildung gewesen, jetzt wird es ein bisschen technischer. Genau, Anonymy

00:55:21.600 --> 00:55:26.760
Kommunikation bezieht sich auf im Prinzip die Metadaten der Kommunikation. Vertrauliche

00:55:26.760 --> 00:55:31.080
Kommunikation hat man schon kennengelernt im Kupto-Kapitel, da geht es darum, dass die Inhalte

00:55:31.080 --> 00:55:37.200
von Nachrichten vertraulich bleiben. Bei Anonymy Kommunikation geht es darum, dass vertraulich

00:55:37.200 --> 00:55:42.640
bleibt, wer mit wem kommuniziert. Nicht notwendigerweise Inhalte der Nachricht. Wenn aus der Inhalt der

00:55:42.640 --> 00:55:47.520
Nachricht klar wird, wer mit wem kommuniziert, ist natÃ¼rlich alles verloren, aber anonym bedeutet,

00:55:47.520 --> 00:55:57.880
dass nicht klar ist, wer mit wem kommuniziert. Das heiÃŸt, man kann auch keine Vertraulichkeit

00:55:57.880 --> 00:56:02.640
haben und auch Vertraulichkeit der Inhalte, die kÃ¶nnen offen sein, aber man kann trotzdem

00:56:02.640 --> 00:56:09.520
AnonymitÃ¤t haben. Die zwei wesentlichen Konzepte, die erfunden worden sind, um Anonymy Kommunikation

00:56:09.520 --> 00:56:14.720
herzustellen, sind DC-Netze und Mix-Verfahren. Beide schauen wir uns jetzt mal an. Fangen wir

00:56:14.720 --> 00:56:19.880
mit den DC-Netzen an. Die sind alle so aus den 1980er Jahren von David Schaum, auch ein berÃ¼hmter

00:56:19.880 --> 00:56:24.840
Kryptograph, erfunden worden in den Grundlagen. Sind da seitdem natÃ¼rlich auch weiterentwickelt

00:56:24.840 --> 00:56:35.120
worden. Fangen wir mit den DC-Netzen an. Das ist eigentlich ein theoretisches Modell, gibt es zwar

00:56:35.120 --> 00:56:41.040
auch praktische Implementierungen davon, aber ein theoretisches Modell, wie man AnonymitÃ¤t und

00:56:41.040 --> 00:56:47.120
zwar perfekte, also informationstheoretisch sichere AnonymitÃ¤t erzeugen kann, in sogenannten

00:56:47.120 --> 00:56:54.360
Broadcast-Netzwerken. Broadcast-Netzwerke sind Netzwerke, wo im Prinzip, wenn einer was sendet,

00:56:54.360 --> 00:57:06.520
sehen das alle gleichzeitig. Das ist jetzt das Szenario. Drei Personen sind da und Alice,

00:57:06.520 --> 00:57:13.040
die jetzt hier so eine TÃ¼te auf dem Kopf hat, die das aus dem Bild anonymen kommunizieren. Das

00:57:13.040 --> 00:57:17.680
Netz ist ein Broadcast-Netz. Alle hÃ¤ngen an der gleichen Leitung dran. Wenn Alice was da drauf

00:57:17.680 --> 00:57:21.640
schreibt, dann sehen das alle. Charlie und Bob kÃ¶nnen natÃ¼rlich auch auf dieses Netz drauf

00:57:21.640 --> 00:57:24.720
schreiben. Die mÃ¼ssen sich natÃ¼rlich irgendwie synchronisieren, dass sie sich nicht in die Quere

00:57:24.720 --> 00:57:30.960
kommen, aber da gibt es andere Technologien, die das herstellen. Und was man jetzt macht im

00:57:31.960 --> 00:57:37.640
DC-Netz ist, dass alle Parteien, die im DC-Netz vorhanden sind, paarweise geheime SchlÃ¼ssel

00:57:37.640 --> 00:57:42.600
austauschen, so wie beim One-Time-Pad Sender und EmpfÃ¤nger einen geheimen SchlÃ¼ssel ausgetauscht

00:57:42.600 --> 00:57:48.440
haben. Hier machen das alle paarweise. Das heiÃŸt Charlie und Alice, Alice und Bob, Bob und Charlie.

00:57:48.440 --> 00:57:56.280
Und ich zeige das jetzt mal auf der nÃ¤chsten Folie, wie dann das Protokoll abgeht, sodass

00:57:56.280 --> 00:58:01.680
man anonym kommunizieren kann. Also wir haben also hier das Broadcast-Netz und hier der SchlÃ¼ssel-Graf.

00:58:01.680 --> 00:58:07.080
Das heiÃŸt, Alice hat mit Bob den roten SchlÃ¼ssel vereinbart, den sieht man hier,

00:58:07.080 --> 00:58:15.720
den blauen SchlÃ¼ssel hier und Charlie mit Bob den dunkelgrÃ¼nen SchlÃ¼ssel, das ist hier.

00:58:15.720 --> 00:58:34.520
So, wenn jetzt jemand was senden will, dann das passiert sozusagen in Runden. Das passiert in

00:58:34.520 --> 00:58:41.680
Runden, das heiÃŸt A, B und C senden nacheinander eine Nachricht und wenn man etwas senden will in

00:58:41.680 --> 00:58:50.640
der Runde, dann sendet man die Nachricht und wenn jemand nichts senden will in eine Runde,

00:58:50.640 --> 00:58:55.800
sendet er die Null-Nachricht. Das heiÃŸt also zum Beispiel Alice mÃ¶chte eine anonyme Nachricht

00:58:55.800 --> 00:59:01.040
senden und zwar diese Nachricht hier und Bob und Charlie mÃ¶chten in der gleichen Runde keine

00:59:01.040 --> 00:59:08.440
Nachricht senden und die senden also die Null. Und was schickt man jetzt auf das Broadcast-Netz?

00:59:09.000 --> 00:59:14.760
Man nimmt die Nachricht, die man versenden will und verixort die mit allen SchlÃ¼sseln von allen

00:59:14.760 --> 00:59:20.520
Partnern, die man im SchlÃ¼ssel-Graf hat. Also zum Beispiel Alice verixort das mit dem blauen

00:59:20.520 --> 00:59:24.080
SchlÃ¼ssel und dem roten SchlÃ¼ssel, also mit dem SchlÃ¼ssel von Bob und SchlÃ¼ssel von Charlie. Und

00:59:24.080 --> 00:59:31.320
das was da rauskommt, das sendet Alice dann per Broadcast, das sehen dann alle. Bob und Charlie,

00:59:31.320 --> 00:59:37.440
die machen das Gleiche mit ihren jeweiligen SchlÃ¼sseln und ihrer Nachricht, die sie senden

00:59:37.440 --> 00:59:43.160
wollen. Und da kommt entsprechend das hier raus. Das ist im Prinzip das XOR der beiden SchlÃ¼ssel,

00:59:43.160 --> 00:59:51.160
die sie mit ihren Partnern miteinander haben. Und was jetzt alle machen ist,

00:59:51.160 --> 00:59:55.280
sie nehmen diese drei Nachrichten, die sie Ã¼ber das Broadcast-Netz empfangen haben und XOR'en die

00:59:55.280 --> 01:00:01.840
mit sich selbst. Das heiÃŸt das XOR dem, XOR dem und da kommt das hier raus. Und da, das ist kein

01:00:01.920 --> 01:00:10.880
Zufall, dass da die Nachricht von Alice rauskommt. Der Grund dafÃ¼r ist, dass alle SchlÃ¼sse, die hier

01:00:10.880 --> 01:00:17.480
reingeixort worden sind, genau zweimal drin vorkommen. Und wenn man einen Wert XOR't auf

01:00:17.480 --> 01:00:21.920
einen beliebigen Wert und dann noch mal XOR't, dann rechnet der sich wieder raus. Das heiÃŸt,

01:00:21.920 --> 01:00:27.320
man zieht die dann im Prinzip immer ab, die SchlÃ¼ssel sind immer zweimal drin und dann

01:00:27.320 --> 01:00:33.000
verschwinden sie wieder aus der XOR-Berechnung. Das heiÃŸt, am Ende ist das hier geixort mit dem

01:00:33.000 --> 01:00:37.880
hier und mit dem hier da drin und natÃ¼rlich wenn man mit 0 XOR't verÃ¤ndert sich nichts. Das heiÃŸt,

01:00:37.880 --> 01:00:45.720
da kommt notwendigerweise das hier raus. Das heiÃŸt, so kann Alice eine Nachricht senden an beide oder

01:00:45.720 --> 01:00:51.080
an alle. Bob und Charlie sehen dann diese Nachricht. Aber jetzt ist die Frage, kÃ¶nnen die nicht

01:00:51.080 --> 01:00:55.320
rauskriegen, dass die von Alice kommt oder nicht? Und das ist das, was wir jetzt als nÃ¤chstes

01:00:55.320 --> 01:01:01.480
anschauen. Erstmal, wer ist jetzt noch dabei bezÃ¼glich der Berechnung? Gut. Also die Frage ist,

01:01:01.480 --> 01:01:08.680
ist das jetzt sicher? Also ist das tatsÃ¤chlich perfekt anonym? Und wir schauen uns jetzt mal an

01:01:08.680 --> 01:01:15.000
aus Sicht des Angreifers. Mal angenommen, Charlie ist der Angreifer. Und wir schauen uns jetzt mal

01:01:15.000 --> 01:01:23.280
nur ein einziges Bit an, was Ã¼bertragen wird. Alice und Bob senden jetzt das, was hier auf

01:01:23.280 --> 01:01:28.360
der Folie steht. Alice sendet eine 0, Bob sendet eine 0, der Angreifer sendet eine 0, also Charlie.

01:01:28.360 --> 01:01:33.720
Und der Angreifer sieht natÃ¼rlich die SchlÃ¼ssel-Bits, die er vereinbart hat. Das Einzige,

01:01:33.720 --> 01:01:42.160
was er nicht weiÃŸ, ist der SchlÃ¼ssel, den Alice und Bob miteinander vereinbart haben. Und jetzt

01:01:42.160 --> 01:01:50.000
ist die Frage, kann er irgendwie rauskriegen, ob Alice oder Bob gesendet haben? Und alles hÃ¤ngt

01:01:50.000 --> 01:01:54.640
im Prinzip davon ab, welchen SchlÃ¼ssel Alice und Bob miteinander vereinbart haben. Da gibt es jetzt

01:01:54.640 --> 01:02:01.440
zwei mÃ¶gliche Szenarien. Das eine Szenario ist, dass der SchlÃ¼ssel zwischen Alice und Bob 0 ist.

01:02:01.440 --> 01:02:11.200
Und in dem Fall wÃ¤re das tatsÃ¤chlich so, dass Alice die 0 schickt, der schickt die 0, der schickt

01:02:11.200 --> 01:02:24.720
die 0. Und wenn Alice, Moment, jetzt muss ich selber nochmal nachgucken. Genau, wenn Alice die

01:02:24.720 --> 01:02:30.760
1 sendet, also wenn Alice sendet, dann verxort das mit dem SchlÃ¼ssel hier und mit dem SchlÃ¼ssel.

01:02:30.760 --> 01:02:36.360
Das heiÃŸt, was Alice gesendet hat, das ist das XOR aus dem Wert, den Alice sendet, der 1 und der

01:02:36.360 --> 01:02:42.680
0. Und da muss 0 rauskommen. In dem Falle ist es tatsÃ¤chlich so, wenn der SchlÃ¼ssel von Alice und

01:02:42.680 --> 01:02:51.960
Bob 0 ist, dann hat Alice die Nachricht gesendet, weil 1 XOR 1 XOR 0 dann 0 ergibt. Wer ist jetzt

01:02:51.960 --> 01:03:01.640
noch dabei? Okay. Wenn der SchlÃ¼ssel allerdings 1 ist, dann kann Alice das nicht geschickt haben,

01:03:01.640 --> 01:03:07.920
dann kann Alice nur die 0 geschickt haben. Dann muss Bob die Nachricht geschickt haben, weil 1 XOR 0

01:03:07.920 --> 01:03:17.520
oder 1 XOR 0 XOR 1 nur die 0 ergibt. Das heiÃŸt, ob jetzt Alice oder Bob geschickt hat, hÃ¤ngt

01:03:17.520 --> 01:03:22.080
einzeln allein von dem Bit-up, von dem SchlÃ¼ssel ab, den Alice und Bob miteinander vereinbart haben.

01:03:22.080 --> 01:03:28.520
Da der aber zufÃ¤llig ist, kann ich nicht vernÃ¼nftig raten als Angreifer. Es kann der ein oder andere

01:03:28.520 --> 01:03:32.360
sein, kann Alice oder Bob sein. Ich kann es nicht rauskriegen. Das Beste, was ich machen kann,

01:03:32.360 --> 01:03:38.080
ist raten. Deswegen sagt man, das Fazit davon ist, das ist informationstheoretisch sicher. Die

01:03:38.080 --> 01:03:43.760
AnonymitÃ¤t ist informationstheoretisch gewÃ¤hrleistet, wenn fÃ¼r jeden Nachrichten-Austausch immer wieder

01:03:43.760 --> 01:03:49.280
ein neuer, geheimer SchlÃ¼ssel vereinbart worden ist. So Ã¤hnlich wie bei One-Time-Pad, wenn Sie sich

01:03:49.280 --> 01:03:52.480
noch daran erinnern, da muss der SchlÃ¼ssel immer so lang sein wie die Nachricht, der muss zufÃ¤llig

01:03:52.480 --> 01:04:00.360
sein und er darf nicht wiederverwendet werden. Das gilt hier genauso. Gut, das ist also perfekte

01:04:00.360 --> 01:04:05.960
AnonymitÃ¤t analog zur informationstheoretischen Sicherheit beim One-Time-Pad. Wer ist jetzt noch

01:04:05.960 --> 01:04:13.400
dabei? Okay, gut. Das war es auch schon zu DC-Netzen. Jetzt schauen wir uns mal Mix-Netzwerke an. Mix-Netzwerke

01:04:13.400 --> 01:04:20.240
sind im Prinzip praktische Alternativen zu DC-Netzen in nachrichtenbasierten Systemen und das sind

01:04:20.240 --> 01:04:26.640
tatsÃ¤chlich praktische Anonymisierungsinstrumente. Also im Prinzip Tor ist auch so eine Art Idee von

01:04:26.640 --> 01:04:33.640
Mix-Netzwerken. Was braucht man bei Mix-Netzwerken? Da braucht man im Prinzip Mix-Knoten. Mix-Knoten

01:04:33.640 --> 01:04:40.840
sind Rechner, die Nachrichten entgegennehmen, die Nachrichten intern verarbeiten und dann Nachrichten

01:04:40.840 --> 01:04:45.920
wieder rausschicken. Die Annahme ist, das Angreifermodell ist, der Angreifer sieht das,

01:04:45.920 --> 01:04:52.000
was in den Mix reingeht und das, was aus dem Mix rauskommt, aber nicht, was in dem Mix selber

01:04:52.000 --> 01:04:57.080
passiert. Wir haben zwar spÃ¤ter noch die MÃ¶glichkeit, dass ein Angreifer auch reingucken hat in das Mix,

01:04:57.080 --> 01:05:01.720
aber in den Mix-Knoten, aber er darf nicht sozusagen in alle Mix-Knoten reinschauen. Das heiÃŸt,

01:05:01.720 --> 01:05:07.800
wir nehmen es erstmal an, er schaut in diesen Mix-Knoten nicht rein. Das heiÃŸt, was macht der

01:05:07.800 --> 01:05:14.880
Mix-Knoten? Der nimmt eine bestimmte Menge von Nachrichten entgegen, streicht da Wiederholungen

01:05:14.880 --> 01:05:20.960
raus. Wiederholungen wÃ¼rde man erkennen sozusagen in der Eingabe und in der Ausgabe. Das heiÃŸt,

01:05:20.960 --> 01:05:28.520
man verhindert dadurch die Verkettung aufgrund von Gleichheit. Dann anschlieÃŸend wartet er auf eine

01:05:28.520 --> 01:05:36.320
bestimmte Menge von Nachrichten, zum Beispiel 10 oder 100. Das vergrÃ¶ÃŸert sozusagen die

01:05:36.320 --> 01:05:44.120
AnnahmetÃ¤tmenge und verhindert, dass man die Nachrichten verketten kann aufgrund der Reihenfolge,

01:05:44.120 --> 01:05:49.120
wie sie reingehen. Das heiÃŸt, wenn eine Nachricht reingeht und man die gleich weiter schickt,

01:05:49.120 --> 01:05:53.680
dann kann der Angreifer sagen, diese Nachricht, die hier reinkommt, ist diese Nachricht,

01:05:53.680 --> 01:05:59.760
die hier rausgeht. Das heiÃŸt, wenn man zum Beispiel 100 Nachrichten sammelt, dann kann man sagen,

01:05:59.760 --> 01:06:04.240
okay, diese 100 Nachrichten, die reingehen, eine von denen, die hier reingeht, ist eine von denen,

01:06:04.240 --> 01:06:12.600
die rausgeht. Da kann man im Prinzip eine von 100 dann raten. Jetzt werden die Nachrichten noch

01:06:12.600 --> 01:06:20.360
umkodiert und Umkodierung sorgt dafÃ¼r, dass die Nachrichten unterschiedlich aussehen. Die

01:06:20.360 --> 01:06:26.560
Nachricht, die reinkommt, wird umkodiert und sieht dann anders aus, wenn sie rausgeht. Und anschlieÃŸend

01:06:26.560 --> 01:06:30.280
werden sie noch umsortiert. Das heiÃŸt, die erste Nachricht, die reingeht, ist nicht die erste

01:06:30.280 --> 01:06:35.200
Nachricht, die rausgeht. Das heiÃŸt, was man dann sieht als Angreifer ist, es gibt eine Menge von

01:06:35.200 --> 01:06:39.760
Nachrichten, die hier reingeht und eine Menge von Nachrichten, die hier rausgeht, aber es gibt keine

01:06:39.760 --> 01:06:43.880
MÃ¶glichkeit zu sagen, diese Nachricht, die reingegangen ist, ist diese Nachricht, die

01:06:43.880 --> 01:06:50.120
rausgegangen ist. Und dadurch verhindert man die Verkettung von Nachrichten. Das heiÃŸt, selbst

01:06:50.120 --> 01:06:55.200
man weiÃŸ, woher die Nachricht hier kommt, man weiÃŸ nicht, wohin die Nachricht hier weitergeht.

01:06:55.200 --> 01:07:03.960
Wer ist jetzt noch dabei? Okay. Man kann natÃ¼rlich mehrere Mixknoten auch hintereinander schalten.

01:07:03.960 --> 01:07:11.920
Also das ist mal hier dargestellt, ein bisschen visueller dargestellt. Also die Form der Nachricht

01:07:11.920 --> 01:07:16.640
ist im Prinzip die Kodierung der Nachricht, wenn man so will. Und da ist auch gleich schon so ein

01:07:16.640 --> 01:07:24.000
Prinzip des schalenmÃ¤ÃŸigen Einschlusses, dieses Zwiebelprinzip, das wir auch gleich noch sehen

01:07:24.000 --> 01:07:29.720
werden. Man kann also auch mehrere Mixe hintereinander schalten. Der Vorteil davon ist,

01:07:29.720 --> 01:07:38.200
dass jedes Mix macht sozusagen das, was ich eben gesagt habe auf der Folie vorher. Aber wenn man

01:07:38.200 --> 01:07:42.520
mehrere Mixe hintereinander schaltet, dann kann man auch noch tolerieren, dass der Angreifer

01:07:42.520 --> 01:07:48.760
ein Mix kontrolliert und reinschauen kann in den Mix. Das heiÃŸt, wenn man mehrere Mixe hat,

01:07:48.760 --> 01:07:54.320
dann ist man sogar noch sicher gegen einen Angreifer, der Mixe kontrolliert, solange der

01:07:54.320 --> 01:08:02.200
Angreifer nicht alle Mixe kontrolliert in der Sequenz. Dass ein nicht angegriffenes Mix reicht,

01:08:02.200 --> 01:08:12.080
um da AnomitÃ¤t herzustellen. Gut, das, was man sich da als Prinzip auch zu nutzen macht,

01:08:12.080 --> 01:08:15.520
ist das sogenannte Onion Routing. Das heiÃŸt also, das sieht man hier so ein bisschen,

01:08:15.520 --> 01:08:21.720
wenn man hier durchrotet, diese Nachricht wird hier umkodiert und diese Nachricht kommt dann

01:08:21.720 --> 01:08:26.280
raus. Die wird dann hier umkodiert, kommt diese Nachricht raus. Man hat immer so Schichten drum und

01:08:26.280 --> 01:08:29.800
das kann man jetzt mit entsprechenden kryptographischen SchlÃ¼sseln vorbereiten.

01:08:29.800 --> 01:08:35.360
Also wenn das hier zum Beispiel Nachricht ist, die rauskommt, die geht durch dieses Mix, durch

01:08:35.360 --> 01:08:39.600
dieses Mix wird sie weitergeleitet und man verschlÃ¼sselt diese Nachricht, man macht da

01:08:39.600 --> 01:08:48.200
so eine Zwiebelschicht drum mit einem geheimen SchlÃ¼ssel, den nur Mix 2 kennt. Und diesen SchlÃ¼ssel,

01:08:48.240 --> 01:08:54.000
der ist vorher mal vereinbart worden und der steckt hier noch sozusagen in der VerschlÃ¼sselung drin.

01:08:54.000 --> 01:09:00.160
Und die Nachricht, die von Mix 1 weitergeleitet wird, da steckt dann auÃŸen noch mal eine

01:09:00.160 --> 01:09:05.160
VerschlÃ¼sselungsschicht drum. Das heiÃŸt, die Nachrichten sind immer so aufgebaut,

01:09:05.160 --> 01:09:10.520
dass immer ein Adressat steht, also an welches Mix es gesendet wird und dann verschlÃ¼sselt,

01:09:10.520 --> 01:09:17.720
wie die Nachricht weitergeleitet werden soll. Also hier steckt drin, erst geht es an A1. A1

01:09:17.720 --> 01:09:24.000
macht dann diese VerschlÃ¼sselungsschicht ab, das ist dieser blaue Kasten. Dann kommt das hier raus

01:09:24.000 --> 01:09:33.560
und Mix 1 schickt das dann weiter und hier macht Mix 2 diesen grÃ¼nen Kasten drum herum weg,

01:09:33.560 --> 01:09:38.840
entschlÃ¼sselt das und da bleibt dann nur Ende M Ã¼brig und das soll dann an eine bestimmte Adresse

01:09:38.840 --> 01:09:43.800
dann weitergeschickt werden. Das kann man sich zunutze machen, wenn man vorher sozusagen mit

01:09:43.800 --> 01:09:48.600
allen Mixknoten in der Sequenz einen geheimen SchlÃ¼ssel vereinbart hat und man verschlÃ¼sselt

01:09:48.600 --> 01:09:54.360
dann prophylaktisch diese Nachricht in der rÃ¼ckwÃ¤rtigen Reihenfolge fÃ¼r die einzelnen

01:09:54.360 --> 01:09:59.680
Mixknoten und macht da immer die Zwiebelschichten drum rum. Deswegen spricht man da von Onion Routing

01:09:59.680 --> 01:10:05.280
und Tor steht ja auch fÃ¼r The Onion Router, da steckt das Prinzip auch drin. Also hier

01:10:05.280 --> 01:10:11.240
noch mal visuell dargestellt, das Ziel steckt hier drin und der Paleout, den man an das Ziel schicken

01:10:11.240 --> 01:10:17.520
will, es geht erstmal um das dritte Mix, da wird also der SchlÃ¼ssel von Mix 3 benutzt,

01:10:17.520 --> 01:10:22.480
der blaue SchlÃ¼ssel, dann der SchlÃ¼ssel von Mix 2, der grÃ¼ne SchlÃ¼ssel und dann der SchlÃ¼ssel

01:10:22.480 --> 01:10:30.000
von Mix 1, der orangen SchlÃ¼ssel. Wenn es dann durch das Netzwerk geht, dann wird in jedem einzelnen

01:10:30.000 --> 01:10:33.640
Schritt bei jedem einzelnen Mix einfach eine Schicht abgemacht mit dem entsprechenden SchlÃ¼ssel,

01:10:33.640 --> 01:10:38.440
der in dem Mix vorhanden ist, dann der grÃ¼ne und dann der blaue und am Ende kommt dann die Nachricht

01:10:38.440 --> 01:10:48.280
raus. Genau, was fÃ¼r Sicherheitseigenschaften garantiert jetzt das Mix? Die Annahme ist,

01:10:48.280 --> 01:10:53.560
der Angreifer sieht tatsÃ¤chlich alle Nachrichten und bei hinreichend hohen Nachrichtenaufkommen

01:10:53.560 --> 01:10:59.360
und sicherer Krypografie ist tatsÃ¤chlich die Zuordnung von Eingangs- zu Ausgangsnachrichten

01:10:59.360 --> 01:11:05.600
auch nur bei einem Mixknoten kann man hinreichend und mÃ¶glich machen, wenn man die AnonymitÃ¤tsmenge,

01:11:05.760 --> 01:11:14.080
die Menge der zwischengespeicherten Nachrichten so groÃŸ macht, wie es sicher sein muss. Also wenn

01:11:14.080 --> 01:11:18.880
man in einer von 100 Nachrichten anonym sein will, dann sammelt man 100 Nachrichten, wenn man in

01:11:18.880 --> 01:11:22.800
einer von 1 Millionen Nachrichten anonym bleiben will, sammelt man in 1 Millionen Nachrichten,

01:11:22.800 --> 01:11:28.000
bevor man weiterleitet. Aber Nachteil ist davon natÃ¼rlich, dass man erstmal 1 Million Nachrichten

01:11:28.000 --> 01:11:35.080
haben muss und warten muss, bis die da sind. Also das ist ein Problem von Mixknoten. Deswegen gibt es

01:11:35.080 --> 01:11:40.960
die sogenannte Low Latency Mix-Dienste wie Tor, die warten nicht unbedingt, bis man diese

01:11:40.960 --> 01:11:45.760
AnonymitÃ¤tsmenge erreicht hat. Die hoffen, dass in der Zwischenzeit mÃ¶glichst viele Nachrichten

01:11:45.760 --> 01:11:50.840
eingegangen sind, aber die kÃ¶nnen es halt nicht garantieren. Die schicken im Prinzip im Interesse,

01:11:50.840 --> 01:11:56.800
dass es schnell geht, die Nachrichten weiter, kriegt dafÃ¼r etwas schwÃ¤chere Sicherheit, dafÃ¼r ist man

01:11:56.800 --> 01:12:03.720
schneller. Und man schÃ¼tzt sich dadurch, dass wenn ein Mix angreifen kann, nimmt man halt mehrere

01:12:03.720 --> 01:12:12.880
Mixknoten und hofft, dass mindestens einer der Mixknoten nicht angreift. So machen wir jetzt noch

01:12:12.880 --> 01:12:18.320
kurz Tor, weil das auch in der Ãœbung drankommt. Also Tor, wer hat schon mal von Tor gehÃ¶rt,

01:12:18.320 --> 01:12:24.560
dem Tor-Netzwerk? Sehr gut. Wer hat schon mal Tor benutzt, den Tor Browser? Auch gut. In der Ãœbung

01:12:24.560 --> 01:12:30.480
werden Sie Tor, den Tor Browser mal benutzen, hoffentlich alle. Tor steht fÃ¼r die Onion Router,

01:12:30.480 --> 01:12:36.480
ist ein Forschungsprojekt, was 2006 in den USA gegrÃ¼ndet worden ist. Gibt es auch einen

01:12:36.480 --> 01:12:40.800
eigenen Verein, der das sozusagen betreibt, ist durch Ã¶ffentliche FÃ¶rdergelder auch finanziert

01:12:40.800 --> 01:12:47.080
worden und wird auch weltweit von einer Menge von Freiwilligen unterstÃ¼tzt, die nÃ¤mlich Mixknoten

01:12:47.080 --> 01:12:54.240
bereitstellen, frei, kostenlos, fÃ¼r die Allgemeinheit. Und es gibt im Tor-Projekt dann auch zum Beispiel

01:12:54.240 --> 01:13:01.440
so eine Statistikseite, wo man sich dann anschauen kann, welche Mixknoten es Ã¼berall gibt.

01:13:01.440 --> 01:13:05.440
Es gibt ein Ã¶ffentliches Verzeichnis von Mixknoten. Hier ist auch mal gezeigt,

01:13:05.440 --> 01:13:09.120
was fÃ¼r Bandbreite die haben. Sie kÃ¶nnen auch bei sich zu Hause sozusagen sehr

01:13:09.120 --> 01:13:13.240
kostengÃ¼nstige Mixknoten bereitstellen, das ist relativ einfach. Das ist mir die

01:13:13.240 --> 01:13:20.320
LÃ¤nderdarstellung. Und ich weiÃŸ nicht, wenn Sie die, das ist hier das Land mit den meisten

01:13:20.320 --> 01:13:28.400
Mixknoten, jedenfalls 2023, zweitmeist und drittmeist. Was ist das Land mit den meisten

01:13:28.400 --> 01:13:39.960
Mixknoten 2023? Raten Sie mal. Deutschland. Es ist immer noch so, heiÃŸt das. Auf dem zweiten

01:13:39.960 --> 01:13:44.640
Platz sind die Vereinigten Staaten und auf dem dritten Platz sind die Niederlande. Also da sieht

01:13:44.640 --> 01:13:51.760
man, wo die Privacy-Aktivisten hocken. Und Tor hat interessanterweise auch was mit Erlangen zu tun,

01:13:51.760 --> 01:13:58.160
weil es gibt die sogenannten Tor Directory Server. Das sind also eine Reihe von Servern,

01:13:58.160 --> 01:14:03.040
ich glaube so ein halbes Dutzend Directory Server. Das sind redundant ausgelegte Server,

01:14:03.040 --> 01:14:13.440
die im Prinzip ein Verzeichnis aller Tor-Relays, aller Mixe enthalten. Das heiÃŸt also auch

01:14:13.440 --> 01:14:20.840
Torknoten kÃ¶nnen sich von dort die Liste der aktuell registrierten Tor-Relays herunterladen.

01:14:20.840 --> 01:14:27.080
Und einer von diesen zentralen Tor Directory Servern wird hier am Rechenzentrum gehostet.

01:14:27.080 --> 01:14:34.440
Deswegen gab es auch mal diese Schlagzeile, die NSA schnÃ¼ffelt in Erlangen in der TATS und auch

01:14:34.440 --> 01:14:43.280
in anderen Nachrichten. Und der Administrator dieses Directory Servers, das ist Sebastian Hahn,

01:14:43.280 --> 01:14:52.160
der auch sozusagen hier der Uni noch zugetan ist, da gab es diese Schlagzeile, das ist der zweite

01:14:52.160 --> 01:14:56.520
Deutsche nach Angela Merkel, der von der NSA ausspioniert worden ist. Da gab es mal eine

01:14:56.520 --> 01:15:02.440
Schlagzeile in Erlanger Nachrichten, weil nÃ¤mlich die IP-Adresse seines Rechners mal in den NSA-Files

01:15:02.440 --> 01:15:09.800
aufgetaucht sind. Okay, so kann man auch eine Schlagzeile machen. So wie funktioniert Tor?

01:15:09.800 --> 01:15:17.960
Tor ist im Prinzip ein Low Latency Mix Netzwerk. Das heiÃŸt Tor sendet Nachrichten weiter Ã¼ber

01:15:17.960 --> 01:15:22.160
sogenannte Tor-Relays, das sind diese Knoten, die jeder betreiben kann, und zwar Ã¼ber einen

01:15:22.160 --> 01:15:28.560
sogenannten Circuit. Und der Circuit besteht aus genau drei Mixknoten. Warum genau drei? Ja,

01:15:28.640 --> 01:15:36.960
das ist so ein Kompromiss aus so viel wie mÃ¶glich und so wenig wie nÃ¶tig. Also man weiÃŸ ja auch,

01:15:36.960 --> 01:15:41.600
dass Nachrichtendienste Tor-Knoten betreiben. Das heiÃŸt, man mÃ¶chte nicht zufÃ¤llig, wenn man nur

01:15:41.600 --> 01:15:48.640
ein Relay von einem Hop hat, dann auf einem Server der NSA landen. Man will mÃ¶glichst drei

01:15:48.640 --> 01:15:54.400
zufÃ¤llige Tor-Relays haben, einen in den Vereinigten Staaten, einen in Russland und einen in China,

01:15:54.400 --> 01:16:00.960
weil man weiÃŸ, die drei kooperieren nicht miteinander. Und dann wird tatsÃ¤chlich Onion

01:16:00.960 --> 01:16:07.320
Routing gemacht, das heiÃŸt, so rÃ¼ckwÃ¤rts verschlÃ¼sselt die Nachricht und dann am Ende

01:16:07.320 --> 01:16:14.720
kommt sie beim sogenannten Exit-Knoten raus und wird dann dort weitergeleitet. Und der Tor-Circuit,

01:16:14.720 --> 01:16:21.360
der wird zufÃ¤llig aufgebaut am Anfang aus dieser groÃŸen Liste an Tor-Knoten, die es gibt, werden

01:16:21.360 --> 01:16:25.920
einfach drei zufÃ¤llig ausgewÃ¤hlt und mit entsprechenden Ã¶ffentlichen SchlÃ¼sseln sind

01:16:25.920 --> 01:16:34.160
die ja dort authentifiziert. Und dann wird der Tor, der Circuit aufgebaut. Und da gibt es sehr

01:16:34.160 --> 01:16:39.640
interessante Protokolle. Das ist mal hier, mÃ¼ssen Sie nicht im Detail verstehen, aber so funktioniert

01:16:39.640 --> 01:16:46.720
das. Das ist mal hier ein Relay, der Ã¼ber zwei Onion-Router aufgebaut wird. Es wird erstmal,

01:16:46.840 --> 01:16:52.200
also jeder von den Links ist jeweils TLS verschlÃ¼sselt, wie das geht, wissen wir vom

01:16:52.200 --> 01:16:59.160
letzten Mal. Und dann wird Ã¼ber TLS wird dann der Tor-Circuit bis zum ersten Relay aufgebaut.

01:16:59.160 --> 01:17:05.160
Da wird dann Ã¼ber die vier Hellmann ein geheimer SchlÃ¼ssel ausgetauscht zwischen dem Client hier,

01:17:05.160 --> 01:17:12.520
Alice, und dem Relay hier. Und dann hat man hier im Prinzip eine gesicherte Verbindung aufgebaut.

01:17:12.680 --> 01:17:20.400
Und Ã¼ber diesen Hop geht man dann, baut man den Circuit weiter auf, geht sozusagen durch diesen

01:17:20.400 --> 01:17:25.200
bis hier in verschlÃ¼sselten Bereich dann zum nÃ¤chsten Onion-Router, baut wieder Ã¼ber die vier

01:17:25.200 --> 01:17:30.280
Hellmann indirekt dann einen geheimen SchlÃ¼ssel zwischen Alice und dem Onion-Router auf. Und dann,

01:17:30.280 --> 01:17:37.400
wenn das tatsÃ¤chlich passiert ist, also hier in der gepunkteten Linie, dann kann Alice, hat gemeinsame

01:17:37.400 --> 01:17:41.800
geheime SchlÃ¼ssel mit dem Onion-Router eins und zwei und kann dann diese Zwiebelnachrichten

01:17:41.800 --> 01:17:49.120
dann aufbauen. Und der Onion-Router 2, der nimmt dann das, was am Ende rauskommt und schickt das an

01:17:49.120 --> 01:17:54.880
die entsprechende Server, der in der Nachricht dann drin steht. Man kann Ã¼ber diese Circuits dann

01:17:54.880 --> 01:18:01.000
im Prinzip, ist wie so ein Tunnel, beliebige TCP-Verbindung aufmachen. Man kann zum Beispiel

01:18:01.000 --> 01:18:08.160
HTTP darÃ¼ber sprechen oder HTTPS darÃ¼ber sprechen. Das Besondere ist, dass die Webseite hier im

01:18:08.240 --> 01:18:14.360
Prinzip als IP-Adresse nicht ihre IP-Adresse hier sieht von Alice, sondern die IP-Adresse des letzten

01:18:14.360 --> 01:18:24.080
Onion Relays, des Exit-Servers. Und so wird dann die IP-Adresse des Senders verschleiert. Man ist

01:18:24.080 --> 01:18:32.120
dadurch dann anonym. Das ist die Idee von Tor. Jetzt gibt es natÃ¼rlich das normale Surfen mit

01:18:32.120 --> 01:18:37.680
Tor. Also man kann den Tor Browser Ã¼ber die Relays, Ã¼ber den Circuit einfach zum normalen

01:18:37.680 --> 01:18:43.240
Surfen im Web benutzen. Der einzige Vorteil, den man hat, ist, dass die eigene IP-Adresse

01:18:43.240 --> 01:18:49.640
verschleiert wird. Jetzt gibt es aber auch noch sogenannte Tor Hidden Services. Das ist das,

01:18:49.640 --> 01:18:58.080
was typischweise als Darknet bezeichnet wird. Da ist es so, dass normalerweise sieht der Server

01:18:58.080 --> 01:19:04.800
nicht die IP-Adresse des Clients, aber man kann jetzt Tor auch dazu benutzen, dass der Client nicht

01:19:04.800 --> 01:19:11.360
die IP-Adresse des Servers sieht. Warum braucht man das? Das braucht man immer dann, wenn der

01:19:11.360 --> 01:19:20.040
Server anonym bleiben mÃ¶chte. Wenn es zum Beispiel ein Server ist, der von irgendeiner verfolgten

01:19:20.040 --> 01:19:24.880
Minderheit in einem autokratischen Staat zum Beispiel betrieben wird, Ã¼ber den sie sich austauschen,

01:19:25.760 --> 01:19:32.560
oder ein Server, der vielleicht anderweitig problematisch fÃ¼r die BehÃ¶rden ist, zum Beispiel

01:19:32.560 --> 01:19:38.040
ein krimineller Server, dann verschleiert er gerne auch seine IP-Adresse. Das geht auch Ã¼ber Tor.

01:19:38.040 --> 01:19:46.720
Das ist relativ komplex, das Protokoll, was da passiert. Ich gehe mal ganz grob drauf ein.

01:19:47.400 --> 01:19:56.880
So ein Tor Hidden Service, also wenn jetzt Bob so einen Hidden Service betreiben will, dann sucht

01:19:56.880 --> 01:20:04.560
er sich drei Tor-Knoten aus, die die Introduction Points sind und annonciert den eigenen Service in

01:20:04.560 --> 01:20:10.160
so einer Datenbank. In dieser Datenbank sagt er was Ã¼ber die Introduction Points und gibt auch noch

01:20:10.160 --> 01:20:19.760
seinen Public Key an. Wenn man jetzt auf diesen Tor Hidden Service zugreifen mÃ¶chte, also kann

01:20:19.760 --> 01:20:27.000
jetzt zum Beispiel Alice in dieser Datenbank nachschlagen, sieht die Introduction Points und

01:20:27.000 --> 01:20:33.760
wÃ¤hlt jetzt selber einen sogenannten Rendezvous-Punkt aus, also baut ein Circuit auf zu einem Rendezvous-Punkt.

01:20:33.760 --> 01:20:44.280
Und diesen Rendezvous-Punkt teilt es dann diesem Introduction Point mit. Was mitgeschickt wird,

01:20:44.280 --> 01:20:51.880
ist noch hier so ein One-Time-Secret, der kommt hier von Alice, wird hier mitgeschickt.

01:20:51.880 --> 01:20:58.480
Und jetzt Ã¼ber diesen Introduction Point kriegt jetzt Bob, der Betreiber des Hidden Services,

01:20:58.480 --> 01:21:06.600
diese Information, das ist mit dem Public Key von Bob verschlÃ¼sselt, den Cookie und den Rendezvous-Punkt.

01:21:06.600 --> 01:21:14.160
Das ist in dem Moment, wo Bob diese Information hat, weiÃŸ er, kennt er den Rendezvous-Punkt und

01:21:14.160 --> 01:21:19.280
baut jetzt selber so ein Circuit auf dazu. Jetzt gibt es also Alice, die ein Circuit zum Rendezvous-Punkt

01:21:19.280 --> 01:21:28.040
hat und Bob, der auch ein Circuit zum Rendezvous-Punkt hat. Und Bob kann jetzt Ã¼ber den Cookie feststellen,

01:21:28.040 --> 01:21:35.080
dass er tatsÃ¤chlich mit Alice spricht. Das heiÃŸt, man hat Ã¼ber zwei Circuits jetzt

01:21:35.080 --> 01:21:41.560
eine beiderseitig anonyme Verbindung aufgebaut. Das heiÃŸt, Alice sieht nicht die IP-Adresse von

01:21:41.560 --> 01:21:49.600
Bob und Bob sieht nicht die IP-Adresse von Alice. Genau, und dann kÃ¶nnen die halt Ã¼ber diesen

01:21:49.600 --> 01:21:55.000
doppelten Circuit, wenn man so will, dann so kommunizieren, wie man standardmÃ¤ÃŸig Ã¼ber Tor

01:21:55.000 --> 01:21:59.400
kommuniziert. Sie kÃ¶nnen HTTP sprechen, alle mÃ¶glichen. Im Prinzip ist es ein Tunnel,

01:21:59.400 --> 01:22:09.480
der Ã¼ber zwei Circuits aufgebaut ist. Gut, jetzt noch vielleicht zusammenfassend, das ist

01:22:09.480 --> 01:22:14.600
mal so eine Grafik von der Tor-Webseite. Das ist mal hier so dargestellt, jetzt sind das sind Sie,

01:22:14.600 --> 01:22:19.680
Sie sitzen zu Hause an Ihrem Wi-Fi, da ist zum Beispiel ein Hacker in Ihrem Wi-Fi drinnen,

01:22:19.680 --> 01:22:24.000
der hÃ¶rt alles mit. Dann geht das Ã¼ber den Interest-Service-Provider, Ã¼ber die Telekom oder

01:22:24.000 --> 01:22:30.240
wer auch immer. Da gibt es natÃ¼rlich Sysadmins, da gibt es die Polizei, die da auch irgendwie Ã¼ber

01:22:30.240 --> 01:22:35.840
TKÃœ-BeschlÃ¼sse ihre Nachricht, ihre Leitung abhÃ¶ren kann. Im Internet sitzen dann die

01:22:35.840 --> 01:22:43.880
Nachrichtendienste und hier beim EmpfÃ¤nger, beim Web-Server, wo sie zum Beispiel Daten abfragen,

01:22:43.880 --> 01:22:49.160
da gibt es natÃ¼rlich genau, also hier site.com, der hat auch einen ISP. Man sieht immer hier in

01:22:49.240 --> 01:22:54.760
den orangenen Punkten, was die alles sehen. Also hier das Unterschieden nach, welche URL wird

01:22:54.760 --> 01:23:03.200
angesurft, welcher User ist das, also die Inhalte und wo sitzt die die entsprechende Person. Location

01:23:03.200 --> 01:23:10.120
heiÃŸt die IP-Adresse, kann man dann rauskriegen. Und im Prinzip, wenn man jetzt hier kein Tor benutzen,

01:23:10.120 --> 01:23:20.000
kein HTTPS, dann sehen alle alles. Also wenn man jetzt HTTPS macht, dann wird ja von hier

01:23:20.000 --> 01:23:28.000
verschlÃ¼sselt bis zum Server. Das heiÃŸt, die Leute auf der Strecke, die sehen die Inhalte nicht,

01:23:28.000 --> 01:23:33.720
aber die sehen, wer mit wem kommuniziert. Und natÃ¼rlich die Server-Betreiber und wenn die

01:23:33.720 --> 01:23:39.800
auch verpflichtet werden von der Polizei, sehen dann wieder alles. Das heiÃŸt, wenn sie Tor nicht

01:23:39.800 --> 01:23:45.520
haben und nur HTTPS benutzen, sind die Inhalte vertraulich. Wenn sie nicht HTTPS benutzen,

01:23:45.520 --> 01:23:50.560
nicht verschlÃ¼sseln, sondern Tor benutzen, dann sieht man, die Quelle und das Ziel sind plÃ¶tzlich

01:23:50.560 --> 01:23:59.800
verborgen, aber die Inhalte sind plÃ¶tzlich wieder da. Und erst wenn sie Tor und HTTPS benutzen,

01:23:59.800 --> 01:24:05.240
sehen im Prinzip die meisten Leute, die hier unterwegs sind, nichts mehr. Nur noch hier am

01:24:05.240 --> 01:24:10.120
Ende sehen natÃ¼rlich die Inhalte, aber sie wissen nicht, woher es kommt. Da sieht man, dass also

01:24:10.120 --> 01:24:14.840
sowohl Tor als auch HTTPS unterschiedliche Schutzstufen einstellen. HTTPS sorgt fÃ¼r die

01:24:14.840 --> 01:24:21.520
VerschlÃ¼sselung, Vertraulichkeit und Tor fÃ¼r die AnonymitÃ¤t. Gut, das war alles, was ich heute

01:24:21.520 --> 01:24:28.120
erzÃ¤hlen wollte. NÃ¤chstes Mal ist dann im neuen Jahr. Ich wÃ¼nsche Ihnen viel Erfolg bei der

01:24:28.120 --> 01:24:31.640
Miniklausur und frohe Weihnachten und wir sehen uns dann im nÃ¤chsten Jahr.



